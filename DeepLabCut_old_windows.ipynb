{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79557792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.8.12\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2da8fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import deeplabcut\n",
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91c76cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created \"C:\\Users\\haosh\\Documents\\Lab\\Behavior\\DeepLabCut\\pupil_test-Hao_Shen-2022-08-04\\videos\"\n",
      "Created \"C:\\Users\\haosh\\Documents\\Lab\\Behavior\\DeepLabCut\\pupil_test-Hao_Shen-2022-08-04\\labeled-data\"\n",
      "Created \"C:\\Users\\haosh\\Documents\\Lab\\Behavior\\DeepLabCut\\pupil_test-Hao_Shen-2022-08-04\\training-datasets\"\n",
      "Created \"C:\\Users\\haosh\\Documents\\Lab\\Behavior\\DeepLabCut\\pupil_test-Hao_Shen-2022-08-04\\dlc-models\"\n",
      "Copying the videos\n",
      "C:\\Users\\haosh\\Documents\\Lab\\Behavior\\DeepLabCut\\pupil_test-Hao_Shen-2022-08-04\\videos\\v24_072922_2031.avi\n",
      "Generated \"C:\\Users\\haosh\\Documents\\Lab\\Behavior\\DeepLabCut\\pupil_test-Hao_Shen-2022-08-04\\config.yaml\"\n",
      "\n",
      "A new project with name pupil_test-Hao_Shen-2022-08-04 is created at C:\\Users\\haosh\\Documents\\Lab\\Behavior\\DeepLabCut and a configurable file (config.yaml) is stored there. Change the parameters in this file to adapt to your project's needs.\n",
      " Once you have changed the configuration file, use the function 'extract_frames' to select frames for labeling.\n",
      ". [OPTIONAL] Use the function 'add_new_videos' to add new videos to your project (at any stage).\n"
     ]
    }
   ],
   "source": [
    "# config_path = deeplabcut.create_new_project('pupil', 'Hao_Shen', ['/home/haosh/Documents/Lab/DeepLabCut/Videos/rigid_0303.avi'], \\\n",
    "#                              working_directory = '/home/haosh/Documents/Lab/DeepLabCut')\n",
    "\n",
    "video_list = [r\"C:\\Users\\haosh\\Documents\\Lab\\Behavior\\DeepLabCut\\Videos\\v24_072922_2031.avi\"]\n",
    "\n",
    "config_path = deeplabcut.create_new_project('pupil_test', 'Hao_Shen', video_list, \\\n",
    "                             working_directory = r'C:\\Users\\haosh\\Documents\\Lab\\Behavior\\DeepLabCut', copy_videos=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6011b026-9be7-4f1a-937c-a5c5c3a0eccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "config_path = r\"C:\\Users\\haosh\\Documents\\Lab\\Behavior\\DeepLabCut\\pupil_test-Hao_Shen-2022-08-04\\config.yaml\"\n",
    "videofile_path  = [config_path[:-12] + r'\\videos']\n",
    "VideoType = 'avi'\n",
    "SHUF = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41048539",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config file read successfully.\n",
      "Do you want to extract (perhaps additional) frames for video: C:\\Users\\haosh\\Documents\\Lab\\Behavior\\DeepLabCut\\pupil_test-Hao_Shen-2022-08-04\\videos\\v24_072922_2031.avi ?\n",
      "yes/noyes\n",
      "Extracting frames based on uniform ...\n",
      "Uniformly extracting of frames from 0.0  seconds to 2122.2  seconds.\n",
      "Frames were successfully extracted, for the videos listed in the config.yaml file.\n",
      "\n",
      "You can now label the frames using the function 'label_frames' (Note, you should label frames extracted from diverse videos (and many videos; we do not recommend training on single videos!)).\n"
     ]
    }
   ],
   "source": [
    "# deeplabcut.extract_frames(conﬁg_path,'automatic','kmeans',crop=False)\n",
    "deeplabcut.extract_frames(conﬁg_path,'automatic','uniform',crop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545dfdbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can now check the labels, using 'check_labels' before proceeding. Then, you can use the function 'create_training_dataset' to create the training dataset.\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.label_frames(conﬁg_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69417df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating images with labels by Hao_Shen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:03<00:00, 16.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If all the labels are ok, then use the function 'create_training_dataset' to create the training dataset!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.check_labels(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f889644-b142-4d74-a12b-ea0d4bbc1f4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training dataset is successfully created. Use the function 'train_network' to start training. Happy training!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.8,\n",
       "  1,\n",
       "  (array([ 8,  2, 48, 15, 10, 41, 12, 18,  0,  9, 34, 39, 40, 36, 27,  1, 38,\n",
       "          17, 28, 13,  6, 42, 31,  3, 33, 20, 47, 44, 22, 25, 29,  4, 46, 26,\n",
       "          11, 30, 45, 35, 43, 49]),\n",
       "   array([19, 32, 24, 23, 21, 37, 16,  5,  7, 14])))]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deeplabcut.create_training_dataset(config_path, net_type='resnet_50', Shuffles=[SHUF], augmenter_type='imgaug')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87f20479-d5ee-4cf5-ad88-117edbc3c253",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 147100 loss: 0.0016 lr: 0.002\n",
      "iteration: 147200 loss: 0.0016 lr: 0.002\n",
      "iteration: 147300 loss: 0.0016 lr: 0.002\n",
      "iteration: 147400 loss: 0.0015 lr: 0.002\n",
      "iteration: 147500 loss: 0.0016 lr: 0.002\n",
      "iteration: 147600 loss: 0.0016 lr: 0.002\n",
      "iteration: 147700 loss: 0.0016 lr: 0.002\n",
      "iteration: 147800 loss: 0.0016 lr: 0.002\n",
      "iteration: 147900 loss: 0.0016 lr: 0.002\n",
      "iteration: 148000 loss: 0.0015 lr: 0.002\n",
      "iteration: 148100 loss: 0.0015 lr: 0.002\n",
      "iteration: 148200 loss: 0.0015 lr: 0.002\n",
      "iteration: 148300 loss: 0.0017 lr: 0.002\n",
      "iteration: 148400 loss: 0.0016 lr: 0.002\n",
      "iteration: 148500 loss: 0.0016 lr: 0.002\n",
      "iteration: 148600 loss: 0.0016 lr: 0.002\n",
      "iteration: 148700 loss: 0.0016 lr: 0.002\n",
      "iteration: 148800 loss: 0.0016 lr: 0.002\n",
      "iteration: 148900 loss: 0.0016 lr: 0.002\n",
      "iteration: 149000 loss: 0.0016 lr: 0.002\n",
      "iteration: 149100 loss: 0.0016 lr: 0.002\n",
      "iteration: 149200 loss: 0.0017 lr: 0.002\n",
      "iteration: 149300 loss: 0.0016 lr: 0.002\n",
      "iteration: 149400 loss: 0.0016 lr: 0.002\n",
      "iteration: 149500 loss: 0.0016 lr: 0.002\n",
      "iteration: 149600 loss: 0.0016 lr: 0.002\n",
      "iteration: 149700 loss: 0.0017 lr: 0.002\n",
      "iteration: 149800 loss: 0.0016 lr: 0.002\n",
      "iteration: 149900 loss: 0.0016 lr: 0.002\n",
      "iteration: 150000 loss: 0.0016 lr: 0.002\n",
      "iteration: 150100 loss: 0.0016 lr: 0.002\n",
      "iteration: 150200 loss: 0.0016 lr: 0.002\n",
      "iteration: 150300 loss: 0.0015 lr: 0.002\n",
      "iteration: 150400 loss: 0.0016 lr: 0.002\n",
      "iteration: 150500 loss: 0.0016 lr: 0.002\n",
      "iteration: 150600 loss: 0.0016 lr: 0.002\n",
      "iteration: 150700 loss: 0.0017 lr: 0.002\n",
      "iteration: 150800 loss: 0.0015 lr: 0.002\n",
      "iteration: 150900 loss: 0.0017 lr: 0.002\n",
      "iteration: 151000 loss: 0.0016 lr: 0.002\n",
      "iteration: 151100 loss: 0.0016 lr: 0.002\n",
      "iteration: 151200 loss: 0.0015 lr: 0.002\n",
      "iteration: 151300 loss: 0.0016 lr: 0.002\n",
      "iteration: 151400 loss: 0.0016 lr: 0.002\n",
      "iteration: 151500 loss: 0.0016 lr: 0.002\n",
      "iteration: 151600 loss: 0.0016 lr: 0.002\n",
      "iteration: 151700 loss: 0.0016 lr: 0.002\n",
      "iteration: 151800 loss: 0.0016 lr: 0.002\n",
      "iteration: 151900 loss: 0.0016 lr: 0.002\n",
      "iteration: 152000 loss: 0.0016 lr: 0.002\n",
      "iteration: 152100 loss: 0.0016 lr: 0.002\n",
      "iteration: 152200 loss: 0.0016 lr: 0.002\n",
      "iteration: 152300 loss: 0.0016 lr: 0.002\n",
      "iteration: 152400 loss: 0.0016 lr: 0.002\n",
      "iteration: 152500 loss: 0.0016 lr: 0.002\n",
      "iteration: 152600 loss: 0.0016 lr: 0.002\n",
      "iteration: 152700 loss: 0.0015 lr: 0.002\n",
      "iteration: 152800 loss: 0.0017 lr: 0.002\n",
      "iteration: 152900 loss: 0.0016 lr: 0.002\n",
      "iteration: 153000 loss: 0.0015 lr: 0.002\n",
      "iteration: 153100 loss: 0.0017 lr: 0.002\n",
      "iteration: 153200 loss: 0.0015 lr: 0.002\n",
      "iteration: 153300 loss: 0.0016 lr: 0.002\n",
      "iteration: 153400 loss: 0.0016 lr: 0.002\n",
      "iteration: 153500 loss: 0.0015 lr: 0.002\n",
      "iteration: 153600 loss: 0.0015 lr: 0.002\n",
      "iteration: 153700 loss: 0.0017 lr: 0.002\n",
      "iteration: 153800 loss: 0.0016 lr: 0.002\n",
      "iteration: 153900 loss: 0.0016 lr: 0.002\n",
      "iteration: 154000 loss: 0.0017 lr: 0.002\n",
      "iteration: 154100 loss: 0.0016 lr: 0.002\n",
      "iteration: 154200 loss: 0.0016 lr: 0.002\n",
      "iteration: 154300 loss: 0.0016 lr: 0.002\n",
      "iteration: 154400 loss: 0.0016 lr: 0.002\n",
      "iteration: 154500 loss: 0.0015 lr: 0.002\n",
      "iteration: 154600 loss: 0.0016 lr: 0.002\n",
      "iteration: 154700 loss: 0.0015 lr: 0.002\n",
      "iteration: 154800 loss: 0.0016 lr: 0.002\n",
      "iteration: 154900 loss: 0.0017 lr: 0.002\n",
      "iteration: 155000 loss: 0.0016 lr: 0.002\n",
      "iteration: 155100 loss: 0.0015 lr: 0.002\n",
      "iteration: 155200 loss: 0.0016 lr: 0.002\n",
      "iteration: 155300 loss: 0.0016 lr: 0.002\n",
      "iteration: 155400 loss: 0.0016 lr: 0.002\n",
      "iteration: 155500 loss: 0.0016 lr: 0.002\n",
      "iteration: 155600 loss: 0.0016 lr: 0.002\n",
      "iteration: 155700 loss: 0.0015 lr: 0.002\n",
      "iteration: 155800 loss: 0.0016 lr: 0.002\n",
      "iteration: 155900 loss: 0.0016 lr: 0.002\n",
      "iteration: 156000 loss: 0.0015 lr: 0.002\n",
      "iteration: 156100 loss: 0.0016 lr: 0.002\n",
      "iteration: 156200 loss: 0.0016 lr: 0.002\n",
      "iteration: 156300 loss: 0.0015 lr: 0.002\n",
      "iteration: 156400 loss: 0.0016 lr: 0.002\n",
      "iteration: 156500 loss: 0.0017 lr: 0.002\n",
      "iteration: 156600 loss: 0.0016 lr: 0.002\n",
      "iteration: 156700 loss: 0.0016 lr: 0.002\n",
      "iteration: 156800 loss: 0.0016 lr: 0.002\n",
      "iteration: 156900 loss: 0.0016 lr: 0.002\n",
      "iteration: 157000 loss: 0.0016 lr: 0.002\n",
      "iteration: 157100 loss: 0.0017 lr: 0.002\n",
      "iteration: 157200 loss: 0.0016 lr: 0.002\n",
      "iteration: 157300 loss: 0.0016 lr: 0.002\n",
      "iteration: 157400 loss: 0.0016 lr: 0.002\n",
      "iteration: 157500 loss: 0.0016 lr: 0.002\n",
      "iteration: 157600 loss: 0.0016 lr: 0.002\n",
      "iteration: 157700 loss: 0.0016 lr: 0.002\n",
      "iteration: 157800 loss: 0.0017 lr: 0.002\n",
      "iteration: 157900 loss: 0.0015 lr: 0.002\n",
      "iteration: 158000 loss: 0.0015 lr: 0.002\n",
      "iteration: 158100 loss: 0.0015 lr: 0.002\n",
      "iteration: 158200 loss: 0.0016 lr: 0.002\n",
      "iteration: 158300 loss: 0.0015 lr: 0.002\n",
      "iteration: 158400 loss: 0.0017 lr: 0.002\n",
      "iteration: 158500 loss: 0.0016 lr: 0.002\n",
      "iteration: 158600 loss: 0.0016 lr: 0.002\n",
      "iteration: 158700 loss: 0.0016 lr: 0.002\n",
      "iteration: 158800 loss: 0.0016 lr: 0.002\n",
      "iteration: 158900 loss: 0.0017 lr: 0.002\n",
      "iteration: 159000 loss: 0.0016 lr: 0.002\n",
      "iteration: 159100 loss: 0.0017 lr: 0.002\n",
      "iteration: 159200 loss: 0.0016 lr: 0.002\n",
      "iteration: 159300 loss: 0.0016 lr: 0.002\n",
      "iteration: 159400 loss: 0.0016 lr: 0.002\n",
      "iteration: 159500 loss: 0.0017 lr: 0.002\n",
      "iteration: 159600 loss: 0.0016 lr: 0.002\n",
      "iteration: 159700 loss: 0.0016 lr: 0.002\n",
      "iteration: 159800 loss: 0.0016 lr: 0.002\n",
      "iteration: 159900 loss: 0.0015 lr: 0.002\n",
      "iteration: 160000 loss: 0.0016 lr: 0.002\n",
      "iteration: 160100 loss: 0.0016 lr: 0.002\n",
      "iteration: 160200 loss: 0.0016 lr: 0.002\n",
      "iteration: 160300 loss: 0.0016 lr: 0.002\n",
      "iteration: 160400 loss: 0.0016 lr: 0.002\n",
      "iteration: 160500 loss: 0.0015 lr: 0.002\n",
      "iteration: 160600 loss: 0.0016 lr: 0.002\n",
      "iteration: 160700 loss: 0.0017 lr: 0.002\n",
      "iteration: 160800 loss: 0.0016 lr: 0.002\n",
      "iteration: 160900 loss: 0.0016 lr: 0.002\n",
      "iteration: 161000 loss: 0.0015 lr: 0.002\n",
      "iteration: 161100 loss: 0.0016 lr: 0.002\n",
      "iteration: 161200 loss: 0.0016 lr: 0.002\n",
      "iteration: 161300 loss: 0.0016 lr: 0.002\n",
      "iteration: 161400 loss: 0.0017 lr: 0.002\n",
      "iteration: 161500 loss: 0.0016 lr: 0.002\n",
      "iteration: 161600 loss: 0.0016 lr: 0.002\n",
      "iteration: 161700 loss: 0.0016 lr: 0.002\n",
      "iteration: 161800 loss: 0.0016 lr: 0.002\n",
      "iteration: 161900 loss: 0.0016 lr: 0.002\n",
      "iteration: 162000 loss: 0.0016 lr: 0.002\n",
      "iteration: 162100 loss: 0.0017 lr: 0.002\n",
      "iteration: 162200 loss: 0.0016 lr: 0.002\n",
      "iteration: 162300 loss: 0.0016 lr: 0.002\n",
      "iteration: 162400 loss: 0.0016 lr: 0.002\n",
      "iteration: 162500 loss: 0.0015 lr: 0.002\n",
      "iteration: 162600 loss: 0.0015 lr: 0.002\n",
      "iteration: 162700 loss: 0.0016 lr: 0.002\n",
      "iteration: 162800 loss: 0.0016 lr: 0.002\n",
      "iteration: 162900 loss: 0.0015 lr: 0.002\n",
      "iteration: 163000 loss: 0.0016 lr: 0.002\n",
      "iteration: 163100 loss: 0.0018 lr: 0.002\n",
      "iteration: 163200 loss: 0.0016 lr: 0.002\n",
      "iteration: 163300 loss: 0.0017 lr: 0.002\n",
      "iteration: 163400 loss: 0.0016 lr: 0.002\n",
      "iteration: 163500 loss: 0.0016 lr: 0.002\n",
      "iteration: 163600 loss: 0.0016 lr: 0.002\n",
      "iteration: 163700 loss: 0.0016 lr: 0.002\n",
      "iteration: 163800 loss: 0.0015 lr: 0.002\n",
      "iteration: 163900 loss: 0.0015 lr: 0.002\n",
      "iteration: 164000 loss: 0.0016 lr: 0.002\n",
      "iteration: 164100 loss: 0.0016 lr: 0.002\n",
      "iteration: 164200 loss: 0.0015 lr: 0.002\n",
      "iteration: 164300 loss: 0.0016 lr: 0.002\n",
      "iteration: 164400 loss: 0.0016 lr: 0.002\n",
      "iteration: 164500 loss: 0.0015 lr: 0.002\n",
      "iteration: 164600 loss: 0.0017 lr: 0.002\n",
      "iteration: 164700 loss: 0.0015 lr: 0.002\n",
      "iteration: 164800 loss: 0.0016 lr: 0.002\n",
      "iteration: 164900 loss: 0.0016 lr: 0.002\n",
      "iteration: 165000 loss: 0.0016 lr: 0.002\n",
      "iteration: 165100 loss: 0.0016 lr: 0.002\n",
      "iteration: 165200 loss: 0.0016 lr: 0.002\n",
      "iteration: 165300 loss: 0.0016 lr: 0.002\n",
      "iteration: 165400 loss: 0.0016 lr: 0.002\n",
      "iteration: 165500 loss: 0.0016 lr: 0.002\n",
      "iteration: 165600 loss: 0.0015 lr: 0.002\n",
      "iteration: 165700 loss: 0.0016 lr: 0.002\n",
      "iteration: 165800 loss: 0.0016 lr: 0.002\n",
      "iteration: 165900 loss: 0.0016 lr: 0.002\n",
      "iteration: 166000 loss: 0.0016 lr: 0.002\n",
      "iteration: 166100 loss: 0.0016 lr: 0.002\n",
      "iteration: 166200 loss: 0.0016 lr: 0.002\n",
      "iteration: 166300 loss: 0.0015 lr: 0.002\n",
      "iteration: 166400 loss: 0.0016 lr: 0.002\n",
      "iteration: 166500 loss: 0.0017 lr: 0.002\n",
      "iteration: 166600 loss: 0.0017 lr: 0.002\n",
      "iteration: 166700 loss: 0.0016 lr: 0.002\n",
      "iteration: 166800 loss: 0.0015 lr: 0.002\n",
      "iteration: 166900 loss: 0.0016 lr: 0.002\n",
      "iteration: 167000 loss: 0.0016 lr: 0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 167100 loss: 0.0015 lr: 0.002\n",
      "iteration: 167200 loss: 0.0016 lr: 0.002\n",
      "iteration: 167300 loss: 0.0016 lr: 0.002\n",
      "iteration: 167400 loss: 0.0016 lr: 0.002\n",
      "iteration: 167500 loss: 0.0015 lr: 0.002\n",
      "iteration: 167600 loss: 0.0015 lr: 0.002\n",
      "iteration: 167700 loss: 0.0017 lr: 0.002\n",
      "iteration: 167800 loss: 0.0017 lr: 0.002\n",
      "iteration: 167900 loss: 0.0014 lr: 0.002\n",
      "iteration: 168000 loss: 0.0016 lr: 0.002\n",
      "iteration: 168100 loss: 0.0017 lr: 0.002\n",
      "iteration: 168200 loss: 0.0016 lr: 0.002\n",
      "iteration: 168300 loss: 0.0016 lr: 0.002\n",
      "iteration: 168400 loss: 0.0016 lr: 0.002\n",
      "iteration: 168500 loss: 0.0016 lr: 0.002\n",
      "iteration: 168600 loss: 0.0016 lr: 0.002\n",
      "iteration: 168700 loss: 0.0016 lr: 0.002\n",
      "iteration: 168800 loss: 0.0016 lr: 0.002\n",
      "iteration: 168900 loss: 0.0016 lr: 0.002\n",
      "iteration: 169000 loss: 0.0016 lr: 0.002\n",
      "iteration: 169100 loss: 0.0016 lr: 0.002\n",
      "iteration: 169200 loss: 0.0016 lr: 0.002\n",
      "iteration: 169300 loss: 0.0016 lr: 0.002\n",
      "iteration: 169400 loss: 0.0017 lr: 0.002\n",
      "iteration: 169500 loss: 0.0015 lr: 0.002\n",
      "iteration: 169600 loss: 0.0016 lr: 0.002\n",
      "iteration: 169700 loss: 0.0016 lr: 0.002\n",
      "iteration: 169800 loss: 0.0016 lr: 0.002\n",
      "iteration: 169900 loss: 0.0016 lr: 0.002\n",
      "iteration: 170000 loss: 0.0016 lr: 0.002\n",
      "iteration: 170100 loss: 0.0016 lr: 0.002\n",
      "iteration: 170200 loss: 0.0015 lr: 0.002\n",
      "iteration: 170300 loss: 0.0016 lr: 0.002\n",
      "iteration: 170400 loss: 0.0016 lr: 0.002\n",
      "iteration: 170500 loss: 0.0016 lr: 0.002\n",
      "iteration: 170600 loss: 0.0016 lr: 0.002\n",
      "iteration: 170700 loss: 0.0015 lr: 0.002\n",
      "iteration: 170800 loss: 0.0015 lr: 0.002\n",
      "iteration: 170900 loss: 0.0016 lr: 0.002\n",
      "iteration: 171000 loss: 0.0016 lr: 0.002\n",
      "iteration: 171100 loss: 0.0015 lr: 0.002\n",
      "iteration: 171200 loss: 0.0016 lr: 0.002\n",
      "iteration: 171300 loss: 0.0015 lr: 0.002\n",
      "iteration: 171400 loss: 0.0016 lr: 0.002\n",
      "iteration: 171500 loss: 0.0017 lr: 0.002\n",
      "iteration: 171600 loss: 0.0018 lr: 0.002\n",
      "iteration: 171700 loss: 0.0016 lr: 0.002\n",
      "iteration: 171800 loss: 0.0016 lr: 0.002\n",
      "iteration: 171900 loss: 0.0016 lr: 0.002\n",
      "iteration: 172000 loss: 0.0016 lr: 0.002\n",
      "iteration: 172100 loss: 0.0015 lr: 0.002\n",
      "iteration: 172200 loss: 0.0016 lr: 0.002\n",
      "iteration: 172300 loss: 0.0015 lr: 0.002\n",
      "iteration: 172400 loss: 0.0015 lr: 0.002\n",
      "iteration: 172500 loss: 0.0015 lr: 0.002\n",
      "iteration: 172600 loss: 0.0016 lr: 0.002\n",
      "iteration: 172700 loss: 0.0016 lr: 0.002\n",
      "iteration: 172800 loss: 0.0015 lr: 0.002\n",
      "iteration: 172900 loss: 0.0017 lr: 0.002\n",
      "iteration: 173000 loss: 0.0016 lr: 0.002\n",
      "iteration: 173100 loss: 0.0016 lr: 0.002\n",
      "iteration: 173200 loss: 0.0015 lr: 0.002\n",
      "iteration: 173300 loss: 0.0017 lr: 0.002\n",
      "iteration: 173400 loss: 0.0016 lr: 0.002\n",
      "iteration: 173500 loss: 0.0016 lr: 0.002\n",
      "iteration: 173600 loss: 0.0015 lr: 0.002\n",
      "iteration: 173700 loss: 0.0015 lr: 0.002\n",
      "iteration: 173800 loss: 0.0015 lr: 0.002\n",
      "iteration: 173900 loss: 0.0016 lr: 0.002\n",
      "iteration: 174000 loss: 0.0015 lr: 0.002\n",
      "iteration: 174100 loss: 0.0016 lr: 0.002\n",
      "iteration: 174200 loss: 0.0016 lr: 0.002\n",
      "iteration: 174300 loss: 0.0016 lr: 0.002\n",
      "iteration: 174400 loss: 0.0015 lr: 0.002\n",
      "iteration: 174500 loss: 0.0016 lr: 0.002\n",
      "iteration: 174600 loss: 0.0016 lr: 0.002\n",
      "iteration: 174700 loss: 0.0016 lr: 0.002\n",
      "iteration: 174800 loss: 0.0016 lr: 0.002\n",
      "iteration: 174900 loss: 0.0017 lr: 0.002\n",
      "iteration: 175000 loss: 0.0015 lr: 0.002\n",
      "iteration: 175100 loss: 0.0016 lr: 0.002\n",
      "iteration: 175200 loss: 0.0016 lr: 0.002\n",
      "iteration: 175300 loss: 0.0016 lr: 0.002\n",
      "iteration: 175400 loss: 0.0016 lr: 0.002\n",
      "iteration: 175500 loss: 0.0016 lr: 0.002\n",
      "iteration: 175600 loss: 0.0016 lr: 0.002\n",
      "iteration: 175700 loss: 0.0016 lr: 0.002\n",
      "iteration: 175800 loss: 0.0015 lr: 0.002\n",
      "iteration: 175900 loss: 0.0015 lr: 0.002\n",
      "iteration: 176000 loss: 0.0016 lr: 0.002\n",
      "iteration: 176100 loss: 0.0016 lr: 0.002\n",
      "iteration: 176200 loss: 0.0017 lr: 0.002\n",
      "iteration: 176300 loss: 0.0016 lr: 0.002\n",
      "iteration: 176400 loss: 0.0017 lr: 0.002\n",
      "iteration: 176500 loss: 0.0017 lr: 0.002\n",
      "iteration: 176600 loss: 0.0016 lr: 0.002\n",
      "iteration: 176700 loss: 0.0015 lr: 0.002\n",
      "iteration: 176800 loss: 0.0016 lr: 0.002\n",
      "iteration: 176900 loss: 0.0016 lr: 0.002\n",
      "iteration: 177000 loss: 0.0017 lr: 0.002\n",
      "iteration: 177100 loss: 0.0015 lr: 0.002\n",
      "iteration: 177200 loss: 0.0016 lr: 0.002\n",
      "iteration: 177300 loss: 0.0016 lr: 0.002\n",
      "iteration: 177400 loss: 0.0016 lr: 0.002\n",
      "iteration: 177500 loss: 0.0015 lr: 0.002\n",
      "iteration: 177600 loss: 0.0016 lr: 0.002\n",
      "iteration: 177700 loss: 0.0016 lr: 0.002\n",
      "iteration: 177800 loss: 0.0016 lr: 0.002\n",
      "iteration: 177900 loss: 0.0016 lr: 0.002\n",
      "iteration: 178000 loss: 0.0017 lr: 0.002\n",
      "iteration: 178100 loss: 0.0016 lr: 0.002\n",
      "iteration: 178200 loss: 0.0015 lr: 0.002\n",
      "iteration: 178300 loss: 0.0016 lr: 0.002\n",
      "iteration: 178400 loss: 0.0016 lr: 0.002\n",
      "iteration: 178500 loss: 0.0016 lr: 0.002\n",
      "iteration: 178600 loss: 0.0016 lr: 0.002\n",
      "iteration: 178700 loss: 0.0017 lr: 0.002\n",
      "iteration: 178800 loss: 0.0016 lr: 0.002\n",
      "iteration: 178900 loss: 0.0015 lr: 0.002\n",
      "iteration: 179000 loss: 0.0016 lr: 0.002\n",
      "iteration: 179100 loss: 0.0016 lr: 0.002\n",
      "iteration: 179200 loss: 0.0016 lr: 0.002\n",
      "iteration: 179300 loss: 0.0015 lr: 0.002\n",
      "iteration: 179400 loss: 0.0015 lr: 0.002\n",
      "iteration: 179500 loss: 0.0016 lr: 0.002\n",
      "iteration: 179600 loss: 0.0016 lr: 0.002\n",
      "iteration: 179700 loss: 0.0016 lr: 0.002\n",
      "iteration: 179800 loss: 0.0016 lr: 0.002\n",
      "iteration: 179900 loss: 0.0016 lr: 0.002\n",
      "iteration: 180000 loss: 0.0016 lr: 0.002\n",
      "iteration: 180100 loss: 0.0016 lr: 0.002\n",
      "iteration: 180200 loss: 0.0015 lr: 0.002\n",
      "iteration: 180300 loss: 0.0016 lr: 0.002\n",
      "iteration: 180400 loss: 0.0016 lr: 0.002\n",
      "iteration: 180500 loss: 0.0015 lr: 0.002\n",
      "iteration: 180600 loss: 0.0015 lr: 0.002\n",
      "iteration: 180700 loss: 0.0015 lr: 0.002\n",
      "iteration: 180800 loss: 0.0017 lr: 0.002\n",
      "iteration: 180900 loss: 0.0016 lr: 0.002\n",
      "iteration: 181000 loss: 0.0016 lr: 0.002\n",
      "iteration: 181100 loss: 0.0016 lr: 0.002\n",
      "iteration: 181200 loss: 0.0015 lr: 0.002\n",
      "iteration: 181300 loss: 0.0016 lr: 0.002\n",
      "iteration: 181400 loss: 0.0016 lr: 0.002\n",
      "iteration: 181500 loss: 0.0016 lr: 0.002\n",
      "iteration: 181600 loss: 0.0016 lr: 0.002\n",
      "iteration: 181700 loss: 0.0016 lr: 0.002\n",
      "iteration: 181800 loss: 0.0016 lr: 0.002\n",
      "iteration: 181900 loss: 0.0015 lr: 0.002\n",
      "iteration: 182000 loss: 0.0015 lr: 0.002\n",
      "iteration: 182100 loss: 0.0015 lr: 0.002\n",
      "iteration: 182200 loss: 0.0015 lr: 0.002\n",
      "iteration: 182300 loss: 0.0017 lr: 0.002\n",
      "iteration: 182400 loss: 0.0015 lr: 0.002\n",
      "iteration: 182500 loss: 0.0017 lr: 0.002\n",
      "iteration: 182600 loss: 0.0016 lr: 0.002\n",
      "iteration: 182700 loss: 0.0015 lr: 0.002\n",
      "iteration: 182800 loss: 0.0016 lr: 0.002\n",
      "iteration: 182900 loss: 0.0016 lr: 0.002\n",
      "iteration: 183000 loss: 0.0016 lr: 0.002\n",
      "iteration: 183100 loss: 0.0015 lr: 0.002\n",
      "iteration: 183200 loss: 0.0015 lr: 0.002\n",
      "iteration: 183300 loss: 0.0015 lr: 0.002\n",
      "iteration: 183400 loss: 0.0016 lr: 0.002\n",
      "iteration: 183500 loss: 0.0016 lr: 0.002\n",
      "iteration: 183600 loss: 0.0016 lr: 0.002\n",
      "iteration: 183700 loss: 0.0017 lr: 0.002\n",
      "iteration: 183800 loss: 0.0016 lr: 0.002\n",
      "iteration: 183900 loss: 0.0016 lr: 0.002\n",
      "iteration: 184000 loss: 0.0017 lr: 0.002\n",
      "iteration: 184100 loss: 0.0015 lr: 0.002\n",
      "iteration: 184200 loss: 0.0017 lr: 0.002\n",
      "iteration: 184300 loss: 0.0016 lr: 0.002\n",
      "iteration: 184400 loss: 0.0016 lr: 0.002\n",
      "iteration: 184500 loss: 0.0016 lr: 0.002\n",
      "iteration: 184600 loss: 0.0016 lr: 0.002\n",
      "iteration: 184700 loss: 0.0016 lr: 0.002\n",
      "iteration: 184800 loss: 0.0016 lr: 0.002\n",
      "iteration: 184900 loss: 0.0016 lr: 0.002\n",
      "iteration: 185000 loss: 0.0016 lr: 0.002\n",
      "iteration: 185100 loss: 0.0016 lr: 0.002\n",
      "iteration: 185200 loss: 0.0015 lr: 0.002\n",
      "iteration: 185300 loss: 0.0016 lr: 0.002\n",
      "iteration: 185400 loss: 0.0017 lr: 0.002\n",
      "iteration: 185500 loss: 0.0016 lr: 0.002\n",
      "iteration: 185600 loss: 0.0015 lr: 0.002\n",
      "iteration: 185700 loss: 0.0016 lr: 0.002\n",
      "iteration: 185800 loss: 0.0016 lr: 0.002\n",
      "iteration: 185900 loss: 0.0017 lr: 0.002\n",
      "iteration: 186000 loss: 0.0016 lr: 0.002\n",
      "iteration: 186100 loss: 0.0016 lr: 0.002\n",
      "iteration: 186200 loss: 0.0016 lr: 0.002\n",
      "iteration: 186300 loss: 0.0016 lr: 0.002\n",
      "iteration: 186400 loss: 0.0016 lr: 0.002\n",
      "iteration: 186500 loss: 0.0016 lr: 0.002\n",
      "iteration: 186600 loss: 0.0016 lr: 0.002\n",
      "iteration: 186700 loss: 0.0017 lr: 0.002\n",
      "iteration: 186800 loss: 0.0017 lr: 0.002\n",
      "iteration: 186900 loss: 0.0016 lr: 0.002\n",
      "iteration: 187000 loss: 0.0016 lr: 0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 187100 loss: 0.0017 lr: 0.002\n",
      "iteration: 187200 loss: 0.0016 lr: 0.002\n",
      "iteration: 187300 loss: 0.0016 lr: 0.002\n",
      "iteration: 187400 loss: 0.0016 lr: 0.002\n",
      "iteration: 187500 loss: 0.0017 lr: 0.002\n",
      "iteration: 187600 loss: 0.0016 lr: 0.002\n",
      "iteration: 187700 loss: 0.0016 lr: 0.002\n",
      "iteration: 187800 loss: 0.0016 lr: 0.002\n",
      "iteration: 187900 loss: 0.0016 lr: 0.002\n",
      "iteration: 188000 loss: 0.0016 lr: 0.002\n",
      "iteration: 188100 loss: 0.0015 lr: 0.002\n",
      "iteration: 188200 loss: 0.0016 lr: 0.002\n",
      "iteration: 188300 loss: 0.0015 lr: 0.002\n",
      "iteration: 188400 loss: 0.0016 lr: 0.002\n",
      "iteration: 188500 loss: 0.0016 lr: 0.002\n",
      "iteration: 188600 loss: 0.0016 lr: 0.002\n",
      "iteration: 188700 loss: 0.0015 lr: 0.002\n",
      "iteration: 188800 loss: 0.0015 lr: 0.002\n",
      "iteration: 188900 loss: 0.0015 lr: 0.002\n",
      "iteration: 189000 loss: 0.0015 lr: 0.002\n",
      "iteration: 189100 loss: 0.0016 lr: 0.002\n",
      "iteration: 189200 loss: 0.0017 lr: 0.002\n",
      "iteration: 189300 loss: 0.0016 lr: 0.002\n",
      "iteration: 189400 loss: 0.0016 lr: 0.002\n",
      "iteration: 189500 loss: 0.0015 lr: 0.002\n",
      "iteration: 189600 loss: 0.0016 lr: 0.002\n",
      "iteration: 189700 loss: 0.0015 lr: 0.002\n",
      "iteration: 189800 loss: 0.0016 lr: 0.002\n",
      "iteration: 189900 loss: 0.0016 lr: 0.002\n",
      "iteration: 190000 loss: 0.0016 lr: 0.002\n",
      "iteration: 190100 loss: 0.0016 lr: 0.002\n",
      "iteration: 190200 loss: 0.0016 lr: 0.002\n",
      "iteration: 190300 loss: 0.0016 lr: 0.002\n",
      "iteration: 190400 loss: 0.0016 lr: 0.002\n",
      "iteration: 190500 loss: 0.0015 lr: 0.002\n",
      "iteration: 190600 loss: 0.0016 lr: 0.002\n",
      "iteration: 190700 loss: 0.0016 lr: 0.002\n",
      "iteration: 190800 loss: 0.0016 lr: 0.002\n",
      "iteration: 190900 loss: 0.0017 lr: 0.002\n",
      "iteration: 191000 loss: 0.0015 lr: 0.002\n",
      "iteration: 191100 loss: 0.0015 lr: 0.002\n",
      "iteration: 191200 loss: 0.0015 lr: 0.002\n",
      "iteration: 191300 loss: 0.0015 lr: 0.002\n",
      "iteration: 191400 loss: 0.0016 lr: 0.002\n",
      "iteration: 191500 loss: 0.0015 lr: 0.002\n",
      "iteration: 191600 loss: 0.0016 lr: 0.002\n",
      "iteration: 191700 loss: 0.0015 lr: 0.002\n",
      "iteration: 191800 loss: 0.0016 lr: 0.002\n",
      "iteration: 191900 loss: 0.0016 lr: 0.002\n",
      "iteration: 192000 loss: 0.0016 lr: 0.002\n",
      "iteration: 192100 loss: 0.0016 lr: 0.002\n",
      "iteration: 192200 loss: 0.0016 lr: 0.002\n",
      "iteration: 192300 loss: 0.0016 lr: 0.002\n",
      "iteration: 192400 loss: 0.0016 lr: 0.002\n",
      "iteration: 192500 loss: 0.0015 lr: 0.002\n",
      "iteration: 192600 loss: 0.0015 lr: 0.002\n",
      "iteration: 192700 loss: 0.0016 lr: 0.002\n",
      "iteration: 192800 loss: 0.0015 lr: 0.002\n",
      "iteration: 192900 loss: 0.0016 lr: 0.002\n",
      "iteration: 193000 loss: 0.0016 lr: 0.002\n",
      "iteration: 193100 loss: 0.0015 lr: 0.002\n",
      "iteration: 193200 loss: 0.0016 lr: 0.002\n",
      "iteration: 193300 loss: 0.0015 lr: 0.002\n",
      "iteration: 193400 loss: 0.0016 lr: 0.002\n",
      "iteration: 193500 loss: 0.0016 lr: 0.002\n",
      "iteration: 193600 loss: 0.0017 lr: 0.002\n",
      "iteration: 193700 loss: 0.0016 lr: 0.002\n",
      "iteration: 193800 loss: 0.0016 lr: 0.002\n",
      "iteration: 193900 loss: 0.0016 lr: 0.002\n",
      "iteration: 194000 loss: 0.0016 lr: 0.002\n",
      "iteration: 194100 loss: 0.0016 lr: 0.002\n",
      "iteration: 194200 loss: 0.0016 lr: 0.002\n",
      "iteration: 194300 loss: 0.0016 lr: 0.002\n",
      "iteration: 194400 loss: 0.0017 lr: 0.002\n",
      "iteration: 194500 loss: 0.0016 lr: 0.002\n",
      "iteration: 194600 loss: 0.0016 lr: 0.002\n",
      "iteration: 194700 loss: 0.0016 lr: 0.002\n",
      "iteration: 194800 loss: 0.0016 lr: 0.002\n",
      "iteration: 194900 loss: 0.0016 lr: 0.002\n",
      "iteration: 195000 loss: 0.0016 lr: 0.002\n",
      "iteration: 195100 loss: 0.0015 lr: 0.002\n",
      "iteration: 195200 loss: 0.0017 lr: 0.002\n",
      "iteration: 195300 loss: 0.0017 lr: 0.002\n",
      "iteration: 195400 loss: 0.0016 lr: 0.002\n",
      "iteration: 195500 loss: 0.0015 lr: 0.002\n",
      "iteration: 195600 loss: 0.0016 lr: 0.002\n",
      "iteration: 195700 loss: 0.0016 lr: 0.002\n",
      "iteration: 195800 loss: 0.0016 lr: 0.002\n",
      "iteration: 195900 loss: 0.0015 lr: 0.002\n",
      "iteration: 196000 loss: 0.0017 lr: 0.002\n",
      "iteration: 196100 loss: 0.0015 lr: 0.002\n",
      "iteration: 196200 loss: 0.0016 lr: 0.002\n",
      "iteration: 196300 loss: 0.0016 lr: 0.002\n",
      "iteration: 196400 loss: 0.0017 lr: 0.002\n",
      "iteration: 196500 loss: 0.0016 lr: 0.002\n",
      "iteration: 196600 loss: 0.0015 lr: 0.002\n",
      "iteration: 196700 loss: 0.0016 lr: 0.002\n",
      "iteration: 196800 loss: 0.0015 lr: 0.002\n",
      "iteration: 196900 loss: 0.0016 lr: 0.002\n",
      "iteration: 197000 loss: 0.0016 lr: 0.002\n",
      "iteration: 197100 loss: 0.0016 lr: 0.002\n",
      "iteration: 197200 loss: 0.0016 lr: 0.002\n",
      "iteration: 197300 loss: 0.0015 lr: 0.002\n",
      "iteration: 197400 loss: 0.0016 lr: 0.002\n",
      "iteration: 197500 loss: 0.0015 lr: 0.002\n",
      "iteration: 197600 loss: 0.0016 lr: 0.002\n",
      "iteration: 197700 loss: 0.0016 lr: 0.002\n",
      "iteration: 197800 loss: 0.0017 lr: 0.002\n",
      "iteration: 197900 loss: 0.0016 lr: 0.002\n",
      "iteration: 198000 loss: 0.0015 lr: 0.002\n",
      "iteration: 198100 loss: 0.0016 lr: 0.002\n",
      "iteration: 198200 loss: 0.0016 lr: 0.002\n",
      "iteration: 198300 loss: 0.0016 lr: 0.002\n",
      "iteration: 198400 loss: 0.0015 lr: 0.002\n",
      "iteration: 198500 loss: 0.0016 lr: 0.002\n",
      "iteration: 198600 loss: 0.0016 lr: 0.002\n",
      "iteration: 198700 loss: 0.0015 lr: 0.002\n",
      "iteration: 198800 loss: 0.0016 lr: 0.002\n",
      "iteration: 198900 loss: 0.0016 lr: 0.002\n",
      "iteration: 199000 loss: 0.0015 lr: 0.002\n",
      "iteration: 199100 loss: 0.0017 lr: 0.002\n",
      "iteration: 199200 loss: 0.0015 lr: 0.002\n",
      "iteration: 199300 loss: 0.0017 lr: 0.002\n",
      "iteration: 199400 loss: 0.0017 lr: 0.002\n",
      "iteration: 199500 loss: 0.0015 lr: 0.002\n",
      "iteration: 199600 loss: 0.0016 lr: 0.002\n",
      "iteration: 199700 loss: 0.0015 lr: 0.002\n",
      "iteration: 199800 loss: 0.0016 lr: 0.002\n",
      "iteration: 199900 loss: 0.0016 lr: 0.002\n",
      "iteration: 200000 loss: 0.0016 lr: 0.002\n",
      "Exception in thread Thread-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\haosh\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1377, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"C:\\Users\\haosh\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1360, in _run_fn\n",
      "    return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n",
      "  File \"C:\\Users\\haosh\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1453, in _call_tf_sessionrun\n",
      "    return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n",
      "tensorflow.python.framework.errors_impl.CancelledError: Enqueue operation was cancelled\n",
      "\t [[{{node fifo_queue_enqueue}}]]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\haosh\\anaconda3\\envs\\DEEPLABCUT\\lib\\threading.py\", line 932, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\haosh\\anaconda3\\envs\\DEEPLABCUT\\lib\\threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\haosh\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\core\\train.py\", line 83, in load_and_enqueue\n",
      "    sess.run(enqueue_op, feed_dict=food)\n",
      "  File \"C:\\Users\\haosh\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 967, in run\n",
      "    result = self._run(None, fetches, feed_dict, options_ptr,\n",
      "  File \"C:\\Users\\haosh\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1190, in _run\n",
      "    results = self._do_run(handle, final_targets, final_fetches,\n",
      "  File \"C:\\Users\\haosh\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1370, in _do_run\n",
      "    return self._do_call(_run_fn, feeds, fetches, targets, options,\n",
      "  File \"C:\\Users\\haosh\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1396, in _do_call\n",
      "    raise type(e)(node_def, op, message)  # pylint: disable=no-value-for-parameter\n",
      "tensorflow.python.framework.errors_impl.CancelledError: Graph execution error:\n",
      "\n",
      "Detected at node 'fifo_queue_enqueue' defined at (most recent call last):\n",
      "    File \"C:\\Users\\haosh\\anaconda3\\envs\\DEEPLABCUT\\lib\\runpy.py\", line 194, in _run_module_as_main\n",
      "      return _run_code(code, main_globals, None,\n",
      "    File \"C:\\Users\\haosh\\anaconda3\\envs\\DEEPLABCUT\\lib\\runpy.py\", line 87, in _run_code\n",
      "      exec(code, run_globals)\n",
      "    File \"C:\\Users\\haosh\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n",
      "      app.launch_new_instance()\n",
      "    File \"C:\\Users\\haosh\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n",
      "      app.start()\n",
      "    File \"C:\\Users\\haosh\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n",
      "      self.io_loop.start()\n",
      "    File \"C:\\Users\\haosh\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n",
      "      self.asyncio_loop.run_forever()\n",
      "    File \"C:\\Users\\haosh\\anaconda3\\envs\\DEEPLABCUT\\lib\\asyncio\\base_events.py\", line 570, in run_forever\n",
      "      self._run_once()\n",
      "    File \"C:\\Users\\haosh\\anaconda3\\envs\\DEEPLABCUT\\lib\\asyncio\\base_events.py\", line 1859, in _run_once\n",
      "      handle._run()\n",
      "    File \"C:\\Users\\haosh\\anaconda3\\envs\\DEEPLABCUT\\lib\\asyncio\\events.py\", line 81, in _run\n",
      "      self._context.run(self._callback, *self._args)\n",
      "    File \"C:\\Users\\haosh\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_queue\n",
      "      await self.process_one()\n",
      "    File \"C:\\Users\\haosh\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 460, in process_one\n",
      "      await dispatch(*args)\n",
      "    File \"C:\\Users\\haosh\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 367, in dispatch_shell\n",
      "      await result\n",
      "    File \"C:\\Users\\haosh\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 662, in execute_request\n",
      "      reply_content = await reply_content\n",
      "    File \"C:\\Users\\haosh\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 360, in do_execute\n",
      "      res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "    File \"C:\\Users\\haosh\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n",
      "      return super().run_cell(*args, **kwargs)\n",
      "    File \"C:\\Users\\haosh\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2854, in run_cell\n",
      "      result = self._run_cell(\n",
      "    File \"C:\\Users\\haosh\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2900, in _run_cell\n",
      "      return runner(coro)\n",
      "    File \"C:\\Users\\haosh\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "      coro.send(None)\n",
      "    File \"C:\\Users\\haosh\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3098, in run_cell_async\n",
      "      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "    File \"C:\\Users\\haosh\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3301, in run_ast_nodes\n",
      "      if await self.run_code(code, result, async_=asy):\n",
      "    File \"C:\\Users\\haosh\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3361, in run_code\n",
      "      exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "    File \"C:\\Users\\haosh\\AppData\\Local\\Temp\\ipykernel_18608\\2915828541.py\", line 1, in <cell line: 1>\n",
      "      deeplabcut.train_network(config_path, shuffle=SHUF, displayiters=100,saveiters=10000)\n",
      "    File \"C:\\Users\\haosh\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\training.py\", line 178, in train_network\n",
      "      train(\n",
      "    File \"C:\\Users\\haosh\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\core\\train.py\", line 169, in train\n",
      "      batch, enqueue_op, placeholders = setup_preloading(batch_spec)\n",
      "    File \"C:\\Users\\haosh\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\core\\train.py\", line 69, in setup_preloading\n",
      "      enqueue_op = q.enqueue(placeholders_list)\n",
      "Node: 'fifo_queue_enqueue'\n",
      "Enqueue operation was cancelled\n",
      "\t [[{{node fifo_queue_enqueue}}]]\n",
      "\n",
      "Original stack trace for 'fifo_queue_enqueue':\n",
      "  File \"C:\\Users\\haosh\\anaconda3\\envs\\DEEPLABCUT\\lib\\runpy.py\", line 194, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Users\\haosh\\anaconda3\\envs\\DEEPLABCUT\\lib\\runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\haosh\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\haosh\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\haosh\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\haosh\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\haosh\\anaconda3\\envs\\DEEPLABCUT\\lib\\asyncio\\base_events.py\", line 570, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\haosh\\anaconda3\\envs\\DEEPLABCUT\\lib\\asyncio\\base_events.py\", line 1859, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\haosh\\anaconda3\\envs\\DEEPLABCUT\\lib\\asyncio\\events.py\", line 81, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\haosh\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\haosh\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 460, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\haosh\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 367, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\haosh\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 662, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\haosh\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 360, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"C:\\Users\\haosh\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\haosh\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2854, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\haosh\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2900, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"C:\\Users\\haosh\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\haosh\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3098, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\haosh\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3301, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\Users\\haosh\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3361, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\haosh\\AppData\\Local\\Temp\\ipykernel_18608\\2915828541.py\", line 1, in <cell line: 1>\n",
      "    deeplabcut.train_network(config_path, shuffle=SHUF, displayiters=100,saveiters=10000)\n",
      "  File \"C:\\Users\\haosh\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\training.py\", line 178, in train_network\n",
      "    train(\n",
      "  File \"C:\\Users\\haosh\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\core\\train.py\", line 169, in train\n",
      "    batch, enqueue_op, placeholders = setup_preloading(batch_spec)\n",
      "  File \"C:\\Users\\haosh\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\core\\train.py\", line 69, in setup_preloading\n",
      "    enqueue_op = q.enqueue(placeholders_list)\n",
      "  File \"C:\\Users\\haosh\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\tensorflow\\python\\ops\\data_flow_ops.py\", line 347, in enqueue\n",
      "    return gen_data_flow_ops.queue_enqueue_v2(\n",
      "  File \"C:\\Users\\haosh\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\tensorflow\\python\\ops\\gen_data_flow_ops.py\", line 4062, in queue_enqueue_v2\n",
      "    _, _, _op, _outputs = _op_def_library._apply_op_helper(\n",
      "  File \"C:\\Users\\haosh\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 740, in _apply_op_helper\n",
      "    op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n",
      "  File \"C:\\Users\\haosh\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3776, in _create_op_internal\n",
      "    ret = Operation(\n",
      "  File \"C:\\Users\\haosh\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2175, in __init__\n",
      "    self._traceback = tf_stack.extract_stack_for_node(self._c_op)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The network is now trained and ready to evaluate. Use the function 'evaluate_network' to evaluate the network.\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.train_network(config_path, shuffle=SHUF, displayiters=100,saveiters=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19a3fc6e-be9b-4ba9-b98d-a3d0c5f5dd7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0],\n",
      "                [1],\n",
      "                [2],\n",
      "                [3],\n",
      "                [4],\n",
      "                [5],\n",
      "                [6],\n",
      "                [7],\n",
      "                [8],\n",
      "                [9],\n",
      "                [10],\n",
      "                [11],\n",
      "                [12],\n",
      "                [13],\n",
      "                [14],\n",
      "                [15]],\n",
      " 'all_joints_names': ['one',\n",
      "                      'two',\n",
      "                      'three',\n",
      "                      'four',\n",
      "                      'five',\n",
      "                      'six',\n",
      "                      'seven',\n",
      "                      'eight',\n",
      "                      'nine',\n",
      "                      'ten',\n",
      "                      'eleven',\n",
      "                      'twelve',\n",
      "                      'thirteen',\n",
      "                      'fourteen',\n",
      "                      'fifteen',\n",
      "                      'sixteen'],\n",
      " 'batch_size': 1,\n",
      " 'crop_pad': 0,\n",
      " 'dataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_pupil_032722May6\\\\pupil_032722_Hao_Shen80shuffle1.mat',\n",
      " 'dataset_type': 'imgaug',\n",
      " 'deterministic': False,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': 'C:\\\\Users\\\\haosh\\\\anaconda3\\\\envs\\\\DEEPLABCUT\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 1.0,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'mirror': False,\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_joints': 16,\n",
      " 'optimizer': 'sgd',\n",
      " 'pairwise_huber_loss': True,\n",
      " 'pairwise_predict': False,\n",
      " 'partaffinityfield_predict': False,\n",
      " 'regularize': False,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': 'C:\\\\Users\\\\haosh\\\\Documents\\\\Lab\\\\Behavior\\\\DeepLabCut\\\\pupil_032722-Hao_Shen-2022-05-06\\\\dlc-models\\\\iteration-0\\\\pupil_032722May6-trainset80shuffle1\\\\test\\\\snapshot',\n",
      " 'stride': 8.0,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using snapshot-200000 for model C:\\Users\\haosh\\Documents\\Lab\\Behavior\\DeepLabCut\\pupil_032722-Hao_Shen-2022-05-06\\dlc-models\\iteration-0\\pupil_032722May6-trainset80shuffle1\n",
      "Analyzing all the videos in the directory...\n",
      "Starting to analyze %  C:\\Users\\haosh\\Documents\\Lab\\Behavior\\DeepLabCut\\pupil_032722-Hao_Shen-2022-05-06\\videos\\pupil_032722.avi\n",
      "Loading  C:\\Users\\haosh\\Documents\\Lab\\Behavior\\DeepLabCut\\pupil_032722-Hao_Shen-2022-05-06\\videos\\pupil_032722.avi\n",
      "Duration of video [s]:  570.5 , recorded with  34.72 fps!\n",
      "Overall # of frames:  19809  found with (before cropping) frame dimensions:  1440 1080\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19998it [12:13, 27.27it/s]                                                                                                                                                                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in C:\\Users\\haosh\\Documents\\Lab\\Behavior\\DeepLabCut\\pupil_032722-Hao_Shen-2022-05-06\\videos...\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'DLC_resnet50_pupil_032722May6shuffle1_200000'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deeplabcut.analyze_videos(config_path, videofile_path, videotype=VideoType, shuffle=SHUF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba94e529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing all the videos in the directory...\n",
      "Filtering with median model C:\\Users\\haosh\\Documents\\Lab\\Behavior\\DeepLabCut\\pupil_032722-Hao_Shen-2022-05-06\\videos\\pupil_032722.avi\n",
      "Saving filtered csv poses!\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.filterpredictions(config_path, videofile_path, videotype=VideoType, shuffle=SHUF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "378fadaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing all the videos in the directory...\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.create_labeled_video(config_path,videofile_path, videotype=VideoType, shuffle=SHUF, filtered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa04505",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
