{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f0119b1-0e9b-43c9-8dc5-205c242845c8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Import Library and Check GPU Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a2da8fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/jialiulab/.conda/envs/DEEPLABCUT/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Python 3.8.13\n",
      "Name: /physical_device:GPU:0   Type: GPU\n"
     ]
    }
   ],
   "source": [
    "!python --version\n",
    "import deeplabcut\n",
    "import tensorflow as tf\n",
    "import yaml\n",
    "import os, glob\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    print(\"Name:\", gpu.name, \"  Type:\", gpu.device_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29d6b4c-ead2-43b7-a918-d3beb802e188",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# If this is a new project to be started, run these cells. Otherwise, skip these cells."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b34b30-5d84-47e1-9489-5efb3c9b6bad",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## *Project Definition*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91c76cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project \"/home/jialiulab/disk1/Hao_Shen_DLC/pupil-Hao Shen-2022-09-17\" already exists!\n"
     ]
    }
   ],
   "source": [
    "# Specify\n",
    "video_list = [r'/home/jialiulab/disk1/Hao_Shen_DLC/Videos/080522_1328.avi']\n",
    "\n",
    "# Specify\n",
    "config_path = deeplabcut.create_new_project('pupil', 'Hao Shen', video_list, \\\n",
    "                             working_directory = r'/home/jialiulab/disk1/Hao_Shen_DLC', copy_videos=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafd9f02-9dae-4817-b08c-39d08fe01df8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## *Other parameters to specify*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b76fe5-4d96-481e-940f-63ad7fe98953",
   "metadata": {},
   "outputs": [],
   "source": [
    "videofile_path  = [config_path[:-12] + r'/videos']\n",
    "VideoType = 'avi'\n",
    "SHUF = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc85772-b538-43df-8847-a0961163fa84",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## *Modify the yaml file to configure project parameters*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "813f2c43-8a43-4348-a646-b8beecfd6386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Task': 'pupil', 'TrainingFraction': [0.8], 'alphavalue': 0.7, 'batch_size': 10, 'bodyparts': ['left', 'right', 'top', 'bottom'], 'colormap': 'rainbow', 'corner2move2': [50, 50], 'cropping': False, 'date': 'Sep17', 'default_augmenter': 'default', 'default_net_type': 'resnet_101', 'dotsize': 12, 'identity': None, 'iteration': 0, 'move2corner': True, 'multianimalproject': False, 'numframes2pick': 50, 'pcutoff': 0.6, 'project_path': '/home/jialiulab/disk1/Hao_Shen_DLC/pupil-Hao Shen-2022-09-17', 'scorer': 'Hao Shen', 'skeleton': [['bodypart1', 'bodypart2'], ['objectA', 'bodypart3']], 'skeleton_color': 'black', 'snapshotindex': -1, 'start': 0, 'stop': 1, 'video_sets': {'/home/jialiulab/disk1/Hao_Shen_DLC/Videos/080522_1328.avi': {'crop': '0, 1440, 0, 1080'}}, 'x1': 0, 'x2': 640, 'y1': 277, 'y2': 624}\n"
     ]
    }
   ],
   "source": [
    "with open(config_path) as file:\n",
    "    # The FullLoader parameter handles the conversion from YAML\n",
    "    # scalar values to Python the dictionary format\n",
    "    l = yaml.load(file, Loader=yaml.FullLoader)\n",
    "    # print(l)\n",
    "    l['bodyparts'] = ['left','right','top','bottom','lefttop', 'righttop', 'leftbottom','rightbottom', \n",
    "                      'left_pupil', 'right_pupil', 'top_pupil', 'bottom_pupil', 'lefttop_pupil',\n",
    "                      'righttop_pupil', 'leftbottom_pupil', 'rightbottom_pupil']\n",
    "    l['numframes2pick'] = 100\n",
    "    l['TrainingFraction'] = [0.8]\n",
    "    l['default_net_type'] = 'resnet_101'\n",
    "    l['batch_size'] = 10\n",
    "    print(l)\n",
    "    \n",
    "with open(config_path, 'w') as file:\n",
    "    documents = yaml.dump(l, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd7773a-043a-4ee3-8668-a17c14b3c629",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## *Extract Frame*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41048539",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config file read successfully.\n",
      "Do you want to extract (perhaps additional) frames for video: /home/jialiulab/disk1/Hao_Shen_DLC/Videos/080522_1328.avi ?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "yes/no yes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frames based on uniform ...\n",
      "Uniformly extracting of frames from 0.0  seconds to 1528.77  seconds.\n",
      "Frames were successfully extracted, for the videos listed in the config.yaml file.\n",
      "\n",
      "You can now label the frames using the function 'label_frames' (Note, you should label frames extracted from diverse videos (and many videos; we do not recommend training on single videos!)).\n"
     ]
    }
   ],
   "source": [
    "# deeplabcut.extract_frames(conﬁg_path,'automatic','kmeans',crop=False)\n",
    "deeplabcut.extract_frames(conﬁg_path,'automatic','kmeans',crop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54f4e6d-304c-4315-97ba-6c73753d9443",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## *Label Frame*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "545dfdbd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can now check the labels, using 'check_labels' before proceeding. Then, you can use the function 'create_training_dataset' to create the training dataset.\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.label_frames(conﬁg_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3187eaa0-6c95-4d79-816e-d0129a468624",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## *Check Labeled Frame (optional)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69417df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deeplabcut.check_labels(config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c271351-cbc3-413d-af9d-2f3cd848273d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## *Train test split*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5f889644-b142-4d74-a12b-ea0d4bbc1f4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training dataset is successfully created. Use the function 'train_network' to start training. Happy training!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.8,\n",
       "  1,\n",
       "  (array([36, 39,  0, 47, 28, 15,  5, 11, 45, 44, 31, 34, 38, 30, 32, 49, 16,\n",
       "          41,  2, 43, 14, 20, 13,  9, 25,  6, 24, 23, 17, 33,  1, 29, 18, 27,\n",
       "          40, 46, 10,  7, 21,  3]),\n",
       "   array([26, 48, 22,  4, 35,  8, 19, 37, 12, 42])))]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deeplabcut.create_training_dataset(config_path, net_type='resnet_101', Shuffles=[SHUF], augmenter_type='imgaug')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0248a8-0d15-4886-9597-78e97b057f99",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## *Modify the yaml file to configure model parameters*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a3fd18c3-1602-4881-846c-0b535755c5f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'all_joints': [[0], [1], [2], [3]], 'all_joints_names': ['left', 'right', 'top', 'bottom'], 'alpha_r': 0.02, 'apply_prob': 0.5, 'batch_size': 2, 'contrast': {'clahe': True, 'claheratio': 0.1, 'histeq': True, 'histeqratio': 0.1}, 'convolution': {'edge': False, 'emboss': {'alpha': [0.0, 1.0], 'strength': [0.5, 1.5]}, 'embossratio': 0.1, 'sharpen': False, 'sharpenratio': 0.3}, 'cropratio': 0.4, 'dataset': 'training-datasets/iteration-0/UnaugmentedDataSet_pupilSep17/pupil_Hao Shen80shuffle1.mat', 'dataset_type': 'imgaug', 'decay_steps': 30000, 'display_iters': 1000, 'global_scale': 0.8, 'init_weights': '/home/jialiulab/.conda/envs/DEEPLABCUT/lib/python3.8/site-packages/deeplabcut/pose_estimation_tensorflow/models/pretrained/resnet_v1_101.ckpt', 'intermediate_supervision': False, 'intermediate_supervision_layer': 12, 'location_refinement': True, 'locref_huber_loss': True, 'locref_loss_weight': 0.05, 'locref_stdev': 7.2801, 'lr_init': 0.0005, 'max_input_size': 1500, 'metadataset': 'training-datasets/iteration-0/UnaugmentedDataSet_pupilSep17/Documentation_data-pupil_80shuffle1.pickle', 'min_input_size': 64, 'mirror': False, 'multi_stage': False, 'multi_step': [[0.02, 10000], [0.01, 50000], [0.002, 200000]], 'net_type': 'resnet_101', 'num_joints': 4, 'pairwise_huber_loss': False, 'pairwise_predict': False, 'partaffinityfield_predict': False, 'pos_dist_thresh': 17, 'project_path': '/home/jialiulab/disk1/Hao_Shen_DLC/pupil-Hao Shen-2022-09-17', 'rotation': 25, 'rotratio': 0.4, 'save_iters': 50000, 'scale_jitter_lo': 0.5, 'scale_jitter_up': 1.25}\n"
     ]
    }
   ],
   "source": [
    "l = [int(string[10:]) for string in os.listdir(config_path[:-12] + f'/dlc-models')]\n",
    "l.sort()\n",
    "\n",
    "model_cfg_path =config_path[:-12] + f'/dlc-models/iteration-{l[-1]}/' \\\n",
    "                + os.listdir(config_path[:-12] + f'/dlc-models/iteration-{l[-1]}')[0] +'/train/pose_cfg.yaml'\n",
    "with open(model_cfg_path) as file:\n",
    "    # The FullLoader parameter handles the conversion from YAML\n",
    "    # scalar values to Python the dictionary format\n",
    "    l = yaml.load(file, Loader=yaml.FullLoader)\n",
    "    print(l)\n",
    "    l['batch_size'] = 2\n",
    "    l['max_input_size'] = 1500\n",
    "    l['net_type'] = 'resnet_101'\n",
    "    l['multi_step'] = [[0.02, 10000], [0.01, 50000], [0.002, 200000]]\n",
    "    \n",
    "with open(model_cfg_path, 'w') as file:\n",
    "    documents = yaml.dump(l, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066625c2-4ea1-4dce-8a00-974c5a1950cc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## *Train*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87f20479-d5ee-4cf5-ad88-117edbc3c253",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0], [1], [2], [3]],\n",
      " 'all_joints_names': ['left', 'right', 'top', 'bottom'],\n",
      " 'alpha_r': 0.02,\n",
      " 'apply_prob': 0.5,\n",
      " 'batch_size': 2,\n",
      " 'contrast': {'clahe': True,\n",
      "              'claheratio': 0.1,\n",
      "              'histeq': True,\n",
      "              'histeqratio': 0.1},\n",
      " 'convolution': {'edge': False,\n",
      "                 'emboss': {'alpha': [0.0, 1.0], 'strength': [0.5, 1.5]},\n",
      "                 'embossratio': 0.1,\n",
      "                 'sharpen': False,\n",
      "                 'sharpenratio': 0.3},\n",
      " 'crop_pad': 0,\n",
      " 'cropratio': 0.4,\n",
      " 'dataset': 'training-datasets/iteration-0/UnaugmentedDataSet_pupilSep17/pupil_Hao '\n",
      "            'Shen80shuffle1.mat',\n",
      " 'dataset_type': 'imgaug',\n",
      " 'decay_steps': 30000,\n",
      " 'deterministic': False,\n",
      " 'display_iters': 1000,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': '/home/jialiulab/.conda/envs/DEEPLABCUT/lib/python3.8/site-packages/deeplabcut/pose_estimation_tensorflow/models/pretrained/resnet_v1_101.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 0.05,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'lr_init': 0.0005,\n",
      " 'max_input_size': 1500,\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'metadataset': 'training-datasets/iteration-0/UnaugmentedDataSet_pupilSep17/Documentation_data-pupil_80shuffle1.pickle',\n",
      " 'min_input_size': 64,\n",
      " 'mirror': False,\n",
      " 'multi_stage': False,\n",
      " 'multi_step': [[0.02, 10], [0.01, 50], [0.002, 200]],\n",
      " 'net_type': 'resnet_101',\n",
      " 'num_joints': 4,\n",
      " 'optimizer': 'sgd',\n",
      " 'pairwise_huber_loss': False,\n",
      " 'pairwise_predict': False,\n",
      " 'partaffinityfield_predict': False,\n",
      " 'pos_dist_thresh': 17,\n",
      " 'project_path': '/home/jialiulab/disk1/Hao_Shen_DLC/pupil-Hao Shen-2022-09-17',\n",
      " 'regularize': False,\n",
      " 'rotation': 25,\n",
      " 'rotratio': 0.4,\n",
      " 'save_iters': 50000,\n",
      " 'scale_jitter_lo': 0.5,\n",
      " 'scale_jitter_up': 1.25,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': '/home/jialiulab/disk1/Hao_Shen_DLC/pupil-Hao '\n",
      "                    'Shen-2022-09-17/dlc-models/iteration-0/pupilSep17-trainset80shuffle1/train/snapshot',\n",
      " 'stride': 8.0,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting single-animal trainer\n",
      "Batch Size is 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jialiulab/.conda/envs/DEEPLABCUT/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ImageNet-pretrained resnet_101\n",
      "Display_iters overwritten as 100\n",
      "Save_iters overwritten as 10000\n",
      "Training parameter:\n",
      "{'stride': 8.0, 'weigh_part_predictions': False, 'weigh_negatives': False, 'fg_fraction': 0.25, 'mean_pixel': [123.68, 116.779, 103.939], 'shuffle': True, 'snapshot_prefix': '/home/jialiulab/disk1/Hao_Shen_DLC/pupil-Hao Shen-2022-09-17/dlc-models/iteration-0/pupilSep17-trainset80shuffle1/train/snapshot', 'log_dir': 'log', 'global_scale': 0.8, 'location_refinement': True, 'locref_stdev': 7.2801, 'locref_loss_weight': 0.05, 'locref_huber_loss': True, 'optimizer': 'sgd', 'intermediate_supervision': False, 'intermediate_supervision_layer': 12, 'regularize': False, 'weight_decay': 0.0001, 'crop_pad': 0, 'scoremap_dir': 'test', 'batch_size': 2, 'dataset_type': 'imgaug', 'deterministic': False, 'mirror': False, 'pairwise_huber_loss': False, 'weigh_only_present_joints': False, 'partaffinityfield_predict': False, 'pairwise_predict': False, 'all_joints': [[0], [1], [2], [3]], 'all_joints_names': ['left', 'right', 'top', 'bottom'], 'alpha_r': 0.02, 'apply_prob': 0.5, 'contrast': {'clahe': True, 'claheratio': 0.1, 'histeq': True, 'histeqratio': 0.1, 'gamma': False, 'sigmoid': False, 'log': False, 'linear': False}, 'convolution': {'edge': False, 'emboss': {'alpha': [0.0, 1.0], 'strength': [0.5, 1.5]}, 'embossratio': 0.1, 'sharpen': False, 'sharpenratio': 0.3}, 'cropratio': 0.4, 'dataset': 'training-datasets/iteration-0/UnaugmentedDataSet_pupilSep17/pupil_Hao Shen80shuffle1.mat', 'decay_steps': 30000, 'display_iters': 1000, 'init_weights': '/home/jialiulab/.conda/envs/DEEPLABCUT/lib/python3.8/site-packages/deeplabcut/pose_estimation_tensorflow/models/pretrained/resnet_v1_101.ckpt', 'lr_init': 0.0005, 'max_input_size': 1500, 'metadataset': 'training-datasets/iteration-0/UnaugmentedDataSet_pupilSep17/Documentation_data-pupil_80shuffle1.pickle', 'min_input_size': 64, 'multi_stage': False, 'multi_step': [[0.02, 10], [0.01, 50], [0.002, 200]], 'net_type': 'resnet_101', 'num_joints': 4, 'pos_dist_thresh': 17, 'project_path': '/home/jialiulab/disk1/Hao_Shen_DLC/pupil-Hao Shen-2022-09-17', 'rotation': 25, 'rotratio': 0.4, 'save_iters': 50000, 'scale_jitter_lo': 0.5, 'scale_jitter_up': 1.25, 'covering': True, 'elastic_transform': True, 'motion_blur': True, 'motion_blur_params': {'k': 7, 'angle': (-90, 90)}}\n",
      "Starting training....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 100 loss: 0.0365 lr: 0.002\n",
      "iteration: 200 loss: 0.0176 lr: 0.002\n",
      "Exception in thread Thread-4:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jialiulab/.conda/envs/DEEPLABCUT/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 1377, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/home/jialiulab/.conda/envs/DEEPLABCUT/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 1360, in _run_fn\n",
      "    return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n",
      "  File \"/home/jialiulab/.conda/envs/DEEPLABCUT/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 1453, in _call_tf_sessionrun\n",
      "    return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n",
      "tensorflow.python.framework.errors_impl.CancelledError: Enqueue operation was cancelled\n",
      "\t [[{{node fifo_queue_enqueue}}]]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jialiulab/.conda/envs/DEEPLABCUT/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/jialiulab/.conda/envs/DEEPLABCUT/lib/python3.8/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/jialiulab/.conda/envs/DEEPLABCUT/lib/python3.8/site-packages/deeplabcut/pose_estimation_tensorflow/core/train.py\", line 83, in load_and_enqueue\n",
      "    sess.run(enqueue_op, feed_dict=food)\n",
      "  File \"/home/jialiulab/.conda/envs/DEEPLABCUT/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 967, in run\n",
      "    result = self._run(None, fetches, feed_dict, options_ptr,\n",
      "  File \"/home/jialiulab/.conda/envs/DEEPLABCUT/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 1190, in _run\n",
      "    results = self._do_run(handle, final_targets, final_fetches,\n",
      "  File \"/home/jialiulab/.conda/envs/DEEPLABCUT/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 1370, in _do_run\n",
      "    return self._do_call(_run_fn, feeds, fetches, targets, options,\n",
      "  File \"/home/jialiulab/.conda/envs/DEEPLABCUT/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 1396, in _do_call\n",
      "    raise type(e)(node_def, op, message)  # pylint: disable=no-value-for-parameter\n",
      "tensorflow.python.framework.errors_impl.CancelledError: Graph execution error:\n",
      "\n",
      "Detected at node 'fifo_queue_enqueue' defined at (most recent call last):\n",
      "    File \"/home/jialiulab/.conda/envs/DEEPLABCUT/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n",
      "      return _run_code(code, main_globals, None,\n",
      "    File \"/home/jialiulab/.conda/envs/DEEPLABCUT/lib/python3.8/runpy.py\", line 87, in _run_code\n",
      "      exec(code, run_globals)\n",
      "    File \"/home/jialiulab/.conda/envs/DEEPLABCUT/lib/python3.8/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "      app.launch_new_instance()\n",
      "    File \"/home/jialiulab/.conda/envs/DEEPLABCUT/lib/python3.8/site-packages/traitlets/config/application.py\", line 976, in launch_instance\n",
      "      app.start()\n",
      "    File \"/home/jialiulab/.conda/envs/DEEPLABCUT/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 619, in start\n",
      "      self.io_loop.start()\n",
      "    File \"/home/jialiulab/.conda/envs/DEEPLABCUT/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 199, in start\n",
      "      self.asyncio_loop.run_forever()\n",
      "    File \"/home/jialiulab/.conda/envs/DEEPLABCUT/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n",
      "      self._run_once()\n",
      "    File \"/home/jialiulab/.conda/envs/DEEPLABCUT/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n",
      "      handle._run()\n",
      "    File \"/home/jialiulab/.conda/envs/DEEPLABCUT/lib/python3.8/asyncio/events.py\", line 81, in _run\n",
      "      self._context.run(self._callback, *self._args)\n",
      "    File \"/home/jialiulab/.conda/envs/DEEPLABCUT/lib/python3.8/site-packages/tornado/ioloop.py\", line 688, in <lambda>\n",
      "      lambda f: self._run_callback(functools.partial(callback, future))\n",
      "    File \"/home/jialiulab/.conda/envs/DEEPLABCUT/lib/python3.8/site-packages/tornado/ioloop.py\", line 741, in _run_callback\n",
      "      ret = callback()\n",
      "    File \"/home/jialiulab/.conda/envs/DEEPLABCUT/lib/python3.8/site-packages/tornado/gen.py\", line 814, in inner\n",
      "      self.ctx_run(self.run)\n",
      "    File \"/home/jialiulab/.conda/envs/DEEPLABCUT/lib/python3.8/site-packages/tornado/gen.py\", line 775, in run\n",
      "      yielded = self.gen.send(value)\n",
      "    File \"/home/jialiulab/.conda/envs/DEEPLABCUT/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 358, in process_one\n",
      "      yield gen.maybe_future(dispatch(*args))\n",
      "    File \"/home/jialiulab/.conda/envs/DEEPLABCUT/lib/python3.8/site-packages/tornado/gen.py\", line 234, in wrapper\n",
      "      yielded = ctx_run(next, result)\n",
      "    File \"/home/jialiulab/.conda/envs/DEEPLABCUT/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n",
      "      yield gen.maybe_future(handler(stream, idents, msg))\n",
      "    File \"/home/jialiulab/.conda/envs/DEEPLABCUT/lib/python3.8/site-packages/tornado/gen.py\", line 234, in wrapper\n",
      "      yielded = ctx_run(next, result)\n",
      "    File \"/home/jialiulab/.conda/envs/DEEPLABCUT/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 536, in execute_request\n",
      "      self.do_execute(\n",
      "    File \"/home/jialiulab/.conda/envs/DEEPLABCUT/lib/python3.8/site-packages/tornado/gen.py\", line 234, in wrapper\n",
      "      yielded = ctx_run(next, result)\n",
      "    File \"/home/jialiulab/.conda/envs/DEEPLABCUT/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n",
      "      res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "    File \"/home/jialiulab/.conda/envs/DEEPLABCUT/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n",
      "      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "    File \"/home/jialiulab/.conda/envs/DEEPLABCUT/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_cell\n",
      "      result = self._run_cell(\n",
      "    File \"/home/jialiulab/.conda/envs/DEEPLABCUT/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2936, in _run_cell\n",
      "      return runner(coro)\n",
      "    File \"/home/jialiulab/.conda/envs/DEEPLABCUT/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "      coro.send(None)\n",
      "    File \"/home/jialiulab/.conda/envs/DEEPLABCUT/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3135, in run_cell_async\n",
      "      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "    File \"/home/jialiulab/.conda/envs/DEEPLABCUT/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3338, in run_ast_nodes\n",
      "      if await self.run_code(code, result, async_=asy):\n",
      "    File \"/home/jialiulab/.conda/envs/DEEPLABCUT/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3398, in run_code\n",
      "      exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "    File \"<ipython-input-5-6735d8eef1ad>\", line 1, in <cell line: 1>\n",
      "      deeplabcut.train_network(config_path, shuffle=SHUF, displayiters=100, saveiters=10000)\n",
      "    File \"/home/jialiulab/.conda/envs/DEEPLABCUT/lib/python3.8/site-packages/deeplabcut/pose_estimation_tensorflow/training.py\", line 210, in train_network\n",
      "      train(\n",
      "    File \"/home/jialiulab/.conda/envs/DEEPLABCUT/lib/python3.8/site-packages/deeplabcut/pose_estimation_tensorflow/core/train.py\", line 168, in train\n",
      "      batch, enqueue_op, placeholders = setup_preloading(batch_spec)\n",
      "    File \"/home/jialiulab/.conda/envs/DEEPLABCUT/lib/python3.8/site-packages/deeplabcut/pose_estimation_tensorflow/core/train.py\", line 69, in setup_preloading\n",
      "      enqueue_op = q.enqueue(placeholders_list)\n",
      "Node: 'fifo_queue_enqueue'\n",
      "Enqueue operation was cancelled\n",
      "\t [[{{node fifo_queue_enqueue}}]]\n",
      "\n",
      "Original stack trace for 'fifo_queue_enqueue':\n",
      "  File \"/home/jialiulab/.conda/envs/DEEPLABCUT/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/home/jialiulab/.conda/envs/DEEPLABCUT/lib/python3.8/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/jialiulab/.conda/envs/DEEPLABCUT/lib/python3.8/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/home/jialiulab/.conda/envs/DEEPLABCUT/lib/python3.8/site-packages/traitlets/config/application.py\", line 976, in launch_instance\n",
      "    app.start()\n",
      "  File \"/home/jialiulab/.conda/envs/DEEPLABCUT/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 619, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/home/jialiulab/.conda/envs/DEEPLABCUT/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 199, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/home/jialiulab/.conda/envs/DEEPLABCUT/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/home/jialiulab/.conda/envs/DEEPLABCUT/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n",
      "    handle._run()\n",
      "  File \"/home/jialiulab/.conda/envs/DEEPLABCUT/lib/python3.8/asyncio/events.py\", line 81, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/home/jialiulab/.conda/envs/DEEPLABCUT/lib/python3.8/site-packages/tornado/ioloop.py\", line 688, in <lambda>\n",
      "    lambda f: self._run_callback(functools.partial(callback, future))\n",
      "  File \"/home/jialiulab/.conda/envs/DEEPLABCUT/lib/python3.8/site-packages/tornado/ioloop.py\", line 741, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/home/jialiulab/.conda/envs/DEEPLABCUT/lib/python3.8/site-packages/tornado/gen.py\", line 814, in inner\n",
      "    self.ctx_run(self.run)\n",
      "  File \"/home/jialiulab/.conda/envs/DEEPLABCUT/lib/python3.8/site-packages/tornado/gen.py\", line 775, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/home/jialiulab/.conda/envs/DEEPLABCUT/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 358, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/home/jialiulab/.conda/envs/DEEPLABCUT/lib/python3.8/site-packages/tornado/gen.py\", line 234, in wrapper\n",
      "    yielded = ctx_run(next, result)\n",
      "  File \"/home/jialiulab/.conda/envs/DEEPLABCUT/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/home/jialiulab/.conda/envs/DEEPLABCUT/lib/python3.8/site-packages/tornado/gen.py\", line 234, in wrapper\n",
      "    yielded = ctx_run(next, result)\n",
      "  File \"/home/jialiulab/.conda/envs/DEEPLABCUT/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 536, in execute_request\n",
      "    self.do_execute(\n",
      "  File \"/home/jialiulab/.conda/envs/DEEPLABCUT/lib/python3.8/site-packages/tornado/gen.py\", line 234, in wrapper\n",
      "    yielded = ctx_run(next, result)\n",
      "  File \"/home/jialiulab/.conda/envs/DEEPLABCUT/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/home/jialiulab/.conda/envs/DEEPLABCUT/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/home/jialiulab/.conda/envs/DEEPLABCUT/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/home/jialiulab/.conda/envs/DEEPLABCUT/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2936, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/home/jialiulab/.conda/envs/DEEPLABCUT/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/home/jialiulab/.conda/envs/DEEPLABCUT/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3135, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/home/jialiulab/.conda/envs/DEEPLABCUT/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3338, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/home/jialiulab/.conda/envs/DEEPLABCUT/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3398, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-5-6735d8eef1ad>\", line 1, in <cell line: 1>\n",
      "    deeplabcut.train_network(config_path, shuffle=SHUF, displayiters=100, saveiters=10000)\n",
      "  File \"/home/jialiulab/.conda/envs/DEEPLABCUT/lib/python3.8/site-packages/deeplabcut/pose_estimation_tensorflow/training.py\", line 210, in train_network\n",
      "    train(\n",
      "  File \"/home/jialiulab/.conda/envs/DEEPLABCUT/lib/python3.8/site-packages/deeplabcut/pose_estimation_tensorflow/core/train.py\", line 168, in train\n",
      "    batch, enqueue_op, placeholders = setup_preloading(batch_spec)\n",
      "  File \"/home/jialiulab/.conda/envs/DEEPLABCUT/lib/python3.8/site-packages/deeplabcut/pose_estimation_tensorflow/core/train.py\", line 69, in setup_preloading\n",
      "    enqueue_op = q.enqueue(placeholders_list)\n",
      "  File \"/home/jialiulab/.conda/envs/DEEPLABCUT/lib/python3.8/site-packages/tensorflow/python/ops/data_flow_ops.py\", line 346, in enqueue\n",
      "    return gen_data_flow_ops.queue_enqueue_v2(\n",
      "  File \"/home/jialiulab/.conda/envs/DEEPLABCUT/lib/python3.8/site-packages/tensorflow/python/ops/gen_data_flow_ops.py\", line 4063, in queue_enqueue_v2\n",
      "    _, _, _op, _outputs = _op_def_library._apply_op_helper(\n",
      "  File \"/home/jialiulab/.conda/envs/DEEPLABCUT/lib/python3.8/site-packages/tensorflow/python/framework/op_def_library.py\", line 797, in _apply_op_helper\n",
      "    op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n",
      "  File \"/home/jialiulab/.conda/envs/DEEPLABCUT/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\", line 3754, in _create_op_internal\n",
      "    ret = Operation(\n",
      "  File \"/home/jialiulab/.conda/envs/DEEPLABCUT/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\", line 2133, in __init__\n",
      "    self._traceback = tf_stack.extract_stack_for_node(self._c_op)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The network is now trained and ready to evaluate. Use the function 'evaluate_network' to evaluate the network.\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.train_network(config_path, shuffle=SHUF, displayiters=100, saveiters=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ac4786-b378-489b-a19e-58e37af01324",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## *Analyze videos*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19a3fc6e-be9b-4ba9-b98d-a3d0c5f5dd7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using snapshot-200000 for model /home/jialiulab/disk1/Hao_Shen_DLC/pupil-Hao Shen-2022-09-15/dlc-models/iteration-0/pupilSep15-trainset80shuffle1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jialiulab/.conda/envs/DEEPLABCUT/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing all the videos in the directory...\n",
      "Starting to analyze %  /home/jialiulab/disk1/Hao_Shen_DLC/pupil-Hao Shen-2022-09-15/videos/080522_1328.avi\n",
      "Loading  /home/jialiulab/disk1/Hao_Shen_DLC/pupil-Hao Shen-2022-09-15/videos/080522_1328.avi\n",
      "Duration of video [s]:  1528.68 , recorded with  34.72 fps!\n",
      "Overall # of frames:  53079  found with (before cropping) frame dimensions:  1440 1080\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 53000/53079 [41:32<00:03, 21.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in /home/jialiulab/disk1/Hao_Shen_DLC/pupil-Hao Shen-2022-09-15/videos...\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'DLC_resnet101_pupilSep15shuffle1_200000'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deeplabcut.analyze_videos(config_path, videofile_path, videotype=VideoType, shuffle=SHUF, batchsize=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba94e529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing all the videos in the directory...\n",
      "Filtering with median model /home/jialiulab/disk1/Hao_Shen_DLC/pupil-Hao Shen-2022-09-15/videos/080522_1328.avi\n",
      "Saving filtered csv poses!\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.filterpredictions(config_path, videofile_path, videotype=VideoType, shuffle=SHUF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "378fadaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing all the videos in the directory...\n",
      "Starting to process video: /home/jialiulab/disk1/Hao_Shen_DLC/pupil-Hao Shen-2022-09-15/videos/080522_1328.avi\n",
      "Loading /home/jialiulab/disk1/Hao_Shen_DLC/pupil-Hao Shen-2022-09-15/videos/080522_1328.avi and data.\n",
      "Duration of video [s]: 1528.68, recorded with 34.72 fps!\n",
      "Overall # of frames: 53079 with cropped frame dimensions: 1440 1080\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53079/53079 [08:25<00:00, 104.91it/s]\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.create_labeled_video(config_path,videofile_path, videotype=VideoType, shuffle=SHUF, filtered=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7387c27-331f-467b-a231-62ab9e359c61",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# If continuously using an existing project (Transfer Learning to New Movies), run from here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0145bd6c-9b2d-48d1-bd86-825652eed555",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## *Project Definition*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6011b026-9be7-4f1a-937c-a5c5c3a0eccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify\n",
    "project_name = 'pupil-Hao Shen-2022-09-17'\n",
    "config_path = r\"/home/jialiulab/disk1/Hao_Shen_DLC/\" + project_name + \"/config.yaml\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b10558d-5aed-4cca-ba49-282846683469",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## *Other parameters to specify*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b200c408-267f-47b1-942c-a1a62f7ba87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "videofile_path  = [config_path[:-12] + r'/videos']\n",
    "VideoType = 'avi'\n",
    "SHUF = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76a87a7-674e-4672-b9da-29bfaa95aa95",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## *Add new videos*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc176e1e-44b4-4572-88e4-a6968c5f6479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to create a symbolic link of the video ...\n",
      "Created the symlink of /home/jialiulab/disk1/Hao_Shen_DLC/Videos/pupil_032722.avi to /home/jialiulab/disk1/Hao_Shen_DLC/pupil-Hao Shen-2022-09-17/videos/pupil_032722.avi\n",
      "New videos were added to the project! Use the function 'extract_frames' to select frames for labeling.\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.add_new_videos(config_path, ['/home/jialiulab/disk1/Hao_Shen_DLC/Videos/pupil_032722.avi'], copy_videos=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5b1e72-93ad-4a1c-9bc6-591f2e00a6d1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## *Modify the yaml file to configure project parameters*\n",
    "- only need to change the numframes2pick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03f3ba19-92c7-4910-aa87-4b9ad474447a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Task': 'pupil', 'scorer': 'Hao Shen', 'date': 'Sep17', 'multianimalproject': False, 'identity': None, 'project_path': '/home/jialiulab/disk1/Hao_Shen_DLC/pupil-Hao Shen-2022-09-17', 'video_sets': {'/home/jialiulab/disk1/Hao_Shen_DLC/Videos/080522_1328.avi': {'crop': '0, 1440, 0, 1080'}, '/home/jialiulab/disk1/Hao_Shen_DLC/Videos/pupil_032722.avi': {'crop': '0, 1440, 0, 1080'}}, 'bodyparts': ['left', 'right', 'top', 'bottom'], 'start': 0, 'stop': 1, 'numframes2pick': 50, 'skeleton': [['bodypart1', 'bodypart2'], ['objectA', 'bodypart3']], 'skeleton_color': 'black', 'pcutoff': 0.6, 'dotsize': 12, 'alphavalue': 0.7, 'colormap': 'rainbow', 'TrainingFraction': [0.8], 'iteration': 0, 'default_net_type': 'resnet_101', 'default_augmenter': 'default', 'snapshotindex': -1, 'batch_size': 10, 'cropping': False, 'x1': 0, 'x2': 640, 'y1': 277, 'y2': 624, 'corner2move2': [50, 50], 'move2corner': True}\n",
      "{'Task': 'pupil', 'scorer': 'Hao Shen', 'date': 'Sep17', 'multianimalproject': False, 'identity': None, 'project_path': '/home/jialiulab/disk1/Hao_Shen_DLC/pupil-Hao Shen-2022-09-17', 'video_sets': {'/home/jialiulab/disk1/Hao_Shen_DLC/Videos/080522_1328.avi': {'crop': '0, 1440, 0, 1080'}, '/home/jialiulab/disk1/Hao_Shen_DLC/Videos/pupil_032722.avi': {'crop': '0, 1440, 0, 1080'}}, 'bodyparts': ['left', 'right', 'top', 'bottom'], 'start': 0, 'stop': 1, 'numframes2pick': 5, 'skeleton': [['bodypart1', 'bodypart2'], ['objectA', 'bodypart3']], 'skeleton_color': 'black', 'pcutoff': 0.6, 'dotsize': 12, 'alphavalue': 0.7, 'colormap': 'rainbow', 'TrainingFraction': [0.8], 'iteration': 0, 'default_net_type': 'resnet_101', 'default_augmenter': 'default', 'snapshotindex': -1, 'batch_size': 10, 'cropping': False, 'x1': 0, 'x2': 640, 'y1': 277, 'y2': 624, 'corner2move2': [50, 50], 'move2corner': True}\n"
     ]
    }
   ],
   "source": [
    "with open(config_path) as file:\n",
    "    # The FullLoader parameter handles the conversion from YAML\n",
    "    # scalar values to Python the dictionary format\n",
    "    l = yaml.load(file, Loader=yaml.FullLoader)\n",
    "    # print(l)\n",
    "    l['numframes2pick'] = 50\n",
    "    print(l)\n",
    "    \n",
    "with open(config_path, 'w') as file:\n",
    "    documents = yaml.dump(l, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb67132-e855-4c02-bb7e-4530f6125fa6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## *Extract Frame*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5be5f5f8-cef2-4eac-a5f3-a98a0b51a855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config file read successfully.\n",
      "Do you want to extract (perhaps additional) frames for video: /home/jialiulab/disk1/Hao_Shen_DLC/Videos/080522_1328.avi ?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "yes/no no\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you want to extract (perhaps additional) frames for video: /home/jialiulab/disk1/Hao_Shen_DLC/Videos/pupil_032722.avi ?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "yes/no yes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frames based on uniform ...\n",
      "Uniformly extracting of frames from 0.0  seconds to 570.54  seconds.\n",
      "Frames were successfully extracted, for the videos listed in the config.yaml file.\n",
      "\n",
      "You can now label the frames using the function 'label_frames' (Note, you should label frames extracted from diverse videos (and many videos; we do not recommend training on single videos!)).\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.extract_frames(conﬁg_path,'automatic','kmeans',crop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b76a78-6708-4901-81fd-77f3a611ae1b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## *Label Frame*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a1da460-4218-419f-985b-f9c4a1d2402e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can now check the labels, using 'check_labels' before proceeding. Then, you can use the function 'create_training_dataset' to create the training dataset.\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.label_frames(conﬁg_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1492819f-2d0e-4e2a-bf27-ec7c573aa685",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## *Merge the newly labeled data with labeled data from previous rounds*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4da30ef0-f021-416b-b09b-19c091b8725d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged data sets and updated refinement iteration to 1.\n",
      "Now you can create a new training set for the expanded annotated images (use create_training_dataset).\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.merge_datasets(config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd10517-cf57-44ac-9708-e379c7664de4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## *Check Labeled Frame (optional)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ecf393bd-381d-4eef-bd22-f7bfc6217e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating images with labels by Hao Shen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:24<00:00,  4.15it/s]\n",
      "100%|██████████| 40/40 [00:08<00:00,  4.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If all the labels are ok, then use the function 'create_training_dataset' to create the training dataset!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# deeplabcut.check_labels(config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691ff837-b1dc-4bc3-b6ce-f3ce7e6360b9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## *Train test split*\n",
    "- Should be performed on the newly merged dataset (i.e. with newly extracted and labeled frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5068877e-0085-4b33-b492-1ec066efddf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training dataset is successfully created. Use the function 'train_network' to start training. Happy training!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.8,\n",
       "  1,\n",
       "  (array([ 9, 40, 39, 19, 17, 16,  1, 31, 18, 10, 50, 54, 14,  2, 22, 24, 47,\n",
       "           4, 36,  3, 11, 37, 21,  7, 33, 27, 43, 42, 25, 26, 12,  5, 23, 13,\n",
       "          20, 35, 44, 34, 32,  8, 41,  6, 45, 51]),\n",
       "   array([53, 15, 48, 52,  0, 38, 30, 49, 29, 46, 28])))]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deeplabcut.create_training_dataset(config_path, net_type='resnet_101', Shuffles=[SHUF], augmenter_type='imgaug')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce41511-6cd6-4522-85eb-3ad2179da8c8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## *Modify the yaml file to configure model parameters*\n",
    "- Make sure to use the already trained model from the previous round (transfer learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160b8f3b-198c-4c4e-ab4f-46dfc656ce6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_model = [int(string[10:]) for string in os.listdir(config_path[:-12] + f'/dlc-models')]\n",
    "l_model.sort()\n",
    "model_cfg_path =config_path[:-12] + f'/dlc-models/iteration-{l_model[-1]}/' \\\n",
    "                + os.listdir(config_path[:-12] + f'/dlc-models/iteration-{l_model[-1]}')[0] +'/train/pose_cfg.yaml'\n",
    "folder_last_iter = config_path[:-12] + f'/dlc-models/iteration-{l_model[-2]}/' \\\n",
    "                + os.listdir(config_path[:-12] + f'/dlc-models/iteration-{l_model[-2]}')[0] +'/train'\n",
    "os.chdir(folder_last_iter)\n",
    "recent_model = -1\n",
    "for file in glob.glob(\"*.meta\"):\n",
    "    if int(file[9:-5]) > recent_model:\n",
    "        recent_model = int(file[9:-5])\n",
    "        \n",
    "with open(model_cfg_path) as file:\n",
    "    # The FullLoader parameter handles the conversion from YAML\n",
    "    # scalar values to Python the dictionary format\n",
    "    l = yaml.load(file, Loader=yaml.FullLoader)\n",
    "    # print(l)\n",
    "    l['batch_size'] = 2\n",
    "    l['max_input_size'] = 1500\n",
    "    l['net_type'] = 'resnet_101'\n",
    "    l['multi_step'] = [[0.01, 10000], [0.002, 50000]]\n",
    "    l['init_weights'] = folder_last_iter + '/' + f'snapshot-{recent_model}' \n",
    "    print(l)\n",
    "with open(model_cfg_path, 'w') as file:\n",
    "    documents = yaml.dump(l, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54427d7-30d1-4e28-a7ee-162404329d19",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## *Train*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec296e26-1a29-40bc-8079-ce654fe68866",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0], [1], [2], [3]],\n",
      " 'all_joints_names': ['left', 'right', 'top', 'bottom'],\n",
      " 'alpha_r': 0.02,\n",
      " 'apply_prob': 0.5,\n",
      " 'batch_size': 2,\n",
      " 'contrast': {'clahe': True,\n",
      "              'claheratio': 0.1,\n",
      "              'histeq': True,\n",
      "              'histeqratio': 0.1},\n",
      " 'convolution': {'edge': False,\n",
      "                 'emboss': {'alpha': [0.0, 1.0], 'strength': [0.5, 1.5]},\n",
      "                 'embossratio': 0.1,\n",
      "                 'sharpen': False,\n",
      "                 'sharpenratio': 0.3},\n",
      " 'crop_pad': 0,\n",
      " 'cropratio': 0.4,\n",
      " 'dataset': 'training-datasets/iteration-1/UnaugmentedDataSet_pupilSep17/pupil_Hao '\n",
      "            'Shen80shuffle1.mat',\n",
      " 'dataset_type': 'imgaug',\n",
      " 'decay_steps': 30000,\n",
      " 'deterministic': False,\n",
      " 'display_iters': 1000,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': '/home/jialiulab/disk1/Hao_Shen_DLC/pupil-Hao '\n",
      "                 'Shen-2022-09-17/dlc-models/iteration-0/pupilSep17-trainset80shuffle1/train/snapshot-200',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 0.05,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'lr_init': 0.0005,\n",
      " 'max_input_size': 1500,\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'metadataset': 'training-datasets/iteration-1/UnaugmentedDataSet_pupilSep17/Documentation_data-pupil_80shuffle1.pickle',\n",
      " 'min_input_size': 64,\n",
      " 'mirror': False,\n",
      " 'multi_stage': False,\n",
      " 'multi_step': [[0.01, 10000], [0.002, 50000]],\n",
      " 'net_type': 'resnet_101',\n",
      " 'num_joints': 4,\n",
      " 'optimizer': 'sgd',\n",
      " 'pairwise_huber_loss': False,\n",
      " 'pairwise_predict': False,\n",
      " 'partaffinityfield_predict': False,\n",
      " 'pos_dist_thresh': 17,\n",
      " 'project_path': '/home/jialiulab/disk1/Hao_Shen_DLC/pupil-Hao Shen-2022-09-17',\n",
      " 'regularize': False,\n",
      " 'rotation': 25,\n",
      " 'rotratio': 0.4,\n",
      " 'save_iters': 50000,\n",
      " 'scale_jitter_lo': 0.5,\n",
      " 'scale_jitter_up': 1.25,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': '/home/jialiulab/disk1/Hao_Shen_DLC/pupil-Hao '\n",
      "                    'Shen-2022-09-17/dlc-models/iteration-1/pupilSep17-trainset80shuffle1/train/snapshot',\n",
      " 'stride': 8.0,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting single-animal trainer\n",
      "Batch Size is 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jialiulab/.conda/envs/DEEPLABCUT/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading already trained DLC with backbone: resnet_101\n",
      "Display_iters overwritten as 100\n",
      "Save_iters overwritten as 10000\n",
      "Training parameter:\n",
      "{'stride': 8.0, 'weigh_part_predictions': False, 'weigh_negatives': False, 'fg_fraction': 0.25, 'mean_pixel': [123.68, 116.779, 103.939], 'shuffle': True, 'snapshot_prefix': '/home/jialiulab/disk1/Hao_Shen_DLC/pupil-Hao Shen-2022-09-17/dlc-models/iteration-1/pupilSep17-trainset80shuffle1/train/snapshot', 'log_dir': 'log', 'global_scale': 0.8, 'location_refinement': True, 'locref_stdev': 7.2801, 'locref_loss_weight': 0.05, 'locref_huber_loss': True, 'optimizer': 'sgd', 'intermediate_supervision': False, 'intermediate_supervision_layer': 12, 'regularize': False, 'weight_decay': 0.0001, 'crop_pad': 0, 'scoremap_dir': 'test', 'batch_size': 2, 'dataset_type': 'imgaug', 'deterministic': False, 'mirror': False, 'pairwise_huber_loss': False, 'weigh_only_present_joints': False, 'partaffinityfield_predict': False, 'pairwise_predict': False, 'all_joints': [[0], [1], [2], [3]], 'all_joints_names': ['left', 'right', 'top', 'bottom'], 'alpha_r': 0.02, 'apply_prob': 0.5, 'contrast': {'clahe': True, 'claheratio': 0.1, 'histeq': True, 'histeqratio': 0.1, 'gamma': False, 'sigmoid': False, 'log': False, 'linear': False}, 'convolution': {'edge': False, 'emboss': {'alpha': [0.0, 1.0], 'strength': [0.5, 1.5]}, 'embossratio': 0.1, 'sharpen': False, 'sharpenratio': 0.3}, 'cropratio': 0.4, 'dataset': 'training-datasets/iteration-1/UnaugmentedDataSet_pupilSep17/pupil_Hao Shen80shuffle1.mat', 'decay_steps': 30000, 'display_iters': 1000, 'init_weights': '/home/jialiulab/disk1/Hao_Shen_DLC/pupil-Hao Shen-2022-09-17/dlc-models/iteration-0/pupilSep17-trainset80shuffle1/train/snapshot-200', 'lr_init': 0.0005, 'max_input_size': 1500, 'metadataset': 'training-datasets/iteration-1/UnaugmentedDataSet_pupilSep17/Documentation_data-pupil_80shuffle1.pickle', 'min_input_size': 64, 'multi_stage': False, 'multi_step': [[0.01, 10000], [0.002, 50000]], 'net_type': 'resnet_101', 'num_joints': 4, 'pos_dist_thresh': 17, 'project_path': '/home/jialiulab/disk1/Hao_Shen_DLC/pupil-Hao Shen-2022-09-17', 'rotation': 25, 'rotratio': 0.4, 'save_iters': 50000, 'scale_jitter_lo': 0.5, 'scale_jitter_up': 1.25, 'covering': True, 'elastic_transform': True, 'motion_blur': True, 'motion_blur_params': {'k': 7, 'angle': (-90, 90)}}\n",
      "Starting training....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 300 loss: 0.0167 lr: 0.01\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.train_network(config_path, shuffle=SHUF, displayiters=100, saveiters=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e0d330-683b-434c-8eeb-bba870fe3df8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## *Analyze videos*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d06baaa-cdf7-4ba7-b74e-e955b1f5c9f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0],\n",
      "                [1],\n",
      "                [2],\n",
      "                [3],\n",
      "                [4],\n",
      "                [5],\n",
      "                [6],\n",
      "                [7],\n",
      "                [8],\n",
      "                [9],\n",
      "                [10],\n",
      "                [11],\n",
      "                [12],\n",
      "                [13],\n",
      "                [14],\n",
      "                [15]],\n",
      " 'all_joints_names': ['left',\n",
      "                      'right',\n",
      "                      'top',\n",
      "                      'bottom',\n",
      "                      'lefttop',\n",
      "                      'righttop',\n",
      "                      'leftbottom',\n",
      "                      'rightbottom',\n",
      "                      'left_pupil',\n",
      "                      'right_pupil',\n",
      "                      'top_pupil',\n",
      "                      'bottom_pupil',\n",
      "                      'lefttop_pupil',\n",
      "                      'righttop_pupil',\n",
      "                      'leftbottom_pupil',\n",
      "                      'rightbottom_pupil'],\n",
      " 'batch_size': 1,\n",
      " 'crop_pad': 0,\n",
      " 'dataset': 'training-datasets/iteration-1/UnaugmentedDataSet_pupilSep15/pupil_Hao '\n",
      "            'Shen80shuffle1.mat',\n",
      " 'dataset_type': 'imgaug',\n",
      " 'deterministic': False,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': '/home/jialiulab/.conda/envs/DEEPLABCUT/lib/python3.8/site-packages/deeplabcut/pose_estimation_tensorflow/models/pretrained/resnet_v1_101.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 1.0,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'mirror': False,\n",
      " 'net_type': 'resnet_101',\n",
      " 'num_joints': 16,\n",
      " 'optimizer': 'sgd',\n",
      " 'pairwise_huber_loss': True,\n",
      " 'pairwise_predict': False,\n",
      " 'partaffinityfield_predict': False,\n",
      " 'regularize': False,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': '/home/jialiulab/disk1/Hao_Shen_DLC/pupil-Hao '\n",
      "                    'Shen-2022-09-15/dlc-models/iteration-1/pupilSep15-trainset80shuffle1/test/snapshot',\n",
      " 'stride': 8.0,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n",
      "/home/jialiulab/.conda/envs/DEEPLABCUT/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using snapshot-250000 for model /home/jialiulab/disk1/Hao_Shen_DLC/pupil-Hao Shen-2022-09-15/dlc-models/iteration-1/pupilSep15-trainset80shuffle1\n",
      "Analyzing all the videos in the directory...\n",
      "Starting to analyze %  /home/jialiulab/disk1/Hao_Shen_DLC/pupil-Hao Shen-2022-09-15/videos/pupil_032722.avi\n",
      "Loading  /home/jialiulab/disk1/Hao_Shen_DLC/pupil-Hao Shen-2022-09-15/videos/pupil_032722.avi\n",
      "Duration of video [s]:  570.5 , recorded with  34.72 fps!\n",
      "Overall # of frames:  19809  found with (before cropping) frame dimensions:  1440 1080\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 19800/19809 [14:18<00:00, 23.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in /home/jialiulab/disk1/Hao_Shen_DLC/pupil-Hao Shen-2022-09-15/videos...\n",
      "Starting to analyze %  /home/jialiulab/disk1/Hao_Shen_DLC/pupil-Hao Shen-2022-09-15/videos/080522_1328.avi\n",
      "Loading  /home/jialiulab/disk1/Hao_Shen_DLC/pupil-Hao Shen-2022-09-15/videos/080522_1328.avi\n",
      "Duration of video [s]:  1528.68 , recorded with  34.72 fps!\n",
      "Overall # of frames:  53079  found with (before cropping) frame dimensions:  1440 1080\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 530/53079 [00:33<37:50, 23.15it/s]"
     ]
    }
   ],
   "source": [
    "deeplabcut.analyze_videos(config_path, videofile_path,\n",
    "                                        videotype=VideoType, shuffle=SHUF, batchsize=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5643da-2f48-4c64-bca7-068244bd46a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.filterpredictions(config_path, [videofile_path+'080522_1328.avi', videofile_path+'pupil_032722.avi'], videotype=VideoType, shuffle=SHUF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b389bfa1-ebb9-4d57-bb1e-7fecb38cad74",
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.create_labeled_video(config_path,[videofile_path+'080522_1328.avi', videofile_path+'pupil_032722.avi'], videotype=VideoType, shuffle=SHUF, filtered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48932049-977a-4b03-951e-c3a854b721a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
